<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on feileo</title>
    <link>https://at7h.com/posts/</link>
    <description>Recent content in Posts on feileo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 17 Sep 2020 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://at7h.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>走进 Python 类的内部</title>
      <link>https://at7h.com/posts/py-classes/</link>
      <pubDate>Thu, 17 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/py-classes/</guid>
      <description>这篇文章和大家一起聊一聊 Python 3.8 中类和对象背后的一些概念和实现原理，主要尝试解释 Python 类和对象属性的存储，函数和方法，描述器，对象内存占用的优化支持，以及继承与属性查找等相关问题。 让我们从一个简单的例子开始： class Employee: outsource = False def __init__(self, department, name): self.department = department self.name = name @property def inservice(self): return self.department is not None def __repr__(self): return f&amp;#34;&amp;lt;Employee: {self.department}-{self.name}&amp;gt;&amp;#34; employee = Employee(&amp;#39;IT&amp;#39;, &amp;#39;bobo&amp;#39;) employee 对象是 Employee 类的一个实例，它有两个属性 department 和 name，其值属于该实例。outsource 是类属性，所有者是类，该类的所有实例对象共享此属性值，这跟其他面向对象语言一致。 更改类变量会影响到该类的所有实例对象： &amp;gt;&amp;gt;&amp;gt; e1 = Employee(&amp;#39;IT&amp;#39;, &amp;#39;bobo&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e2 = Employee(&amp;#39;HR&amp;#39;, &amp;#39;cici&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e1.outsource, e2.outsource (False, False) &amp;gt;&amp;gt;&amp;gt; Employee.outsource = True &amp;gt;&amp;gt;&amp;gt; e1.outsource, e2.outsource &amp;gt;&amp;gt;&amp;gt; (True, True) 这仅限于从类更改，当我们从实例更改类变量时： &amp;gt;&amp;gt;&amp;gt; e1 = Employee(&amp;#39;IT&amp;#39;, &amp;#39;bobo&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e2 = Employee(&amp;#39;HR&amp;#39;, &amp;#39;cici&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e1.outsource, e2.outsource (False, False) &amp;gt;&amp;gt;&amp;gt; e1.outsource = True &amp;gt;&amp;gt;&amp;gt; e1.outsource, e2.outsource (True, False) 是的，当你试图从实例对象修改类变量时，Python 不会更改该类的类变量值，而是创建一个同名的实例属性，这是非常正确且安全的。在搜索属性值时，实例变量会优先于类变量，这将在继承与属性查找一节中详细解释。 值得特别注意的是，当类变量的类型是可变类型时，你是从实例对象中更改的它们的： &amp;gt;&amp;gt;&amp;gt; class S: ... L = [1, 2] ... &amp;gt;&amp;gt;&amp;gt; s1, s2 = S(), S() &amp;gt;&amp;gt;&amp;gt; s1.L, s2.L ([1, 2], [1, 2]) &amp;gt;&amp;gt;&amp;gt; t1.L.append(3) &amp;gt;&amp;gt;&amp;gt; t1.L, s2.L ([1, 2, 3], [1, 2, 3]) 好的实践方式是应当尽量的避免这样的设计。 属性的存储 本小节我们一起来看看 Python 中的类属性、方法及实例属性是如何关联存储的。 实例属性 在 Python 中，所有实例属性都存储在 __dict__ 字典中，这就是一个常规的 dict，对于实例属性的维护即是从该字典中获取和修改，它对开发者是完全开放的。 &amp;gt;&amp;gt;&amp;gt; e = Employee(&amp;#39;IT&amp;#39;, &amp;#39;bobo&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e.__dict__ {&amp;#39;department&amp;#39;: &amp;#39;IT&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;} &amp;gt;&amp;gt;&amp;gt; type(e.__dict__) dict &amp;gt;&amp;gt;&amp;gt; e.name is e.__dict__[&amp;#39;name&amp;#39;] True &amp;gt;&amp;gt;&amp;gt; e.__dict__[&amp;#39;department&amp;#39;] = &amp;#39;HR&amp;#39; &amp;gt;&amp;gt;&amp;gt; e.department &amp;#39;HR&amp;#39; 正因为实例属性是采用字典来存储，所以任何时候我们都可以方便的给对象添加或删除字段： &amp;gt;&amp;gt;&amp;gt; e.age = 30 # 并没有定义 age 属性 &amp;gt;&amp;gt;&amp;gt; e.age 30 &amp;gt;&amp;gt;&amp;gt; e.__dict__ {&amp;#39;department&amp;#39;: &amp;#39;IT&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;, &amp;#39;age&amp;#39;: 30} &amp;gt;&amp;gt;&amp;gt; del e.age &amp;gt;&amp;gt;&amp;gt; e.__dict__ {&amp;#39;department&amp;#39;: &amp;#39;IT&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;d&amp;#39;} 我们也可以从字典中实例化一个对象，或者通过保存实例的 __dict__ 来恢复实例。 &amp;gt;&amp;gt;&amp;gt; def new_employee_from(d): ... instance = object.__new__(Employee) ... instance.__dict__.update(d) ... return instance ... &amp;gt;&amp;gt;&amp;gt; e1 = new_employee_from({&amp;#39;department&amp;#39;: &amp;#39;IT&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;}) &amp;gt;&amp;gt;&amp;gt; e1 &amp;lt;Employee: IT-bobo&amp;gt; &amp;gt;&amp;gt;&amp;gt; state = e1.__dict__.copy() &amp;gt;&amp;gt;&amp;gt; del e1 &amp;gt;&amp;gt;&amp;gt; e2 = new_employee_from(state) &amp;gt;&amp;gt;&amp;gt; e2 &amp;gt;&amp;gt;&amp;gt; &amp;lt;Employee: IT-bobo&amp;gt; 因为 __dict__ 的完全开放，所以我们可以向其中添加任何 immutable 类型的 key，比如数字： &amp;gt;&amp;gt;&amp;gt; e.__dict__[1] = 1 &amp;gt;&amp;gt;&amp;gt; e.__dict__ {&amp;#39;department&amp;#39;: &amp;#39;IT&amp;#39;, &amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;, 1: 1} 这些非字符串的字段是我们无法通过实例对象访问的，为了确保不会出现这样的情况，除非必要的情况下，一般最好不要直接对 __dict__ 进行写操作，甚至不要直接操作 __dict__。 所以有一种说法是 Python is a &amp;ldquo;consenting adults language&amp;rdquo;。 这种动态的实现使得我们的代码非常灵活，很多时候非常的便利，但这也付出了存储和性能上的开销。所以 Python 也提供了另外一种机制(__slots__)来放弃使用 __dict__，以节约内存，提高性能，详见 __slots__ 一节。 类属性 同样的，类属性也在存储在类的 __dict__ 字典中： &amp;gt;&amp;gt;&amp;gt; Employee.__dict__ mappingproxy({&amp;#39;__module__&amp;#39;: &amp;#39;__main__&amp;#39;, &amp;#39;outsource&amp;#39;: True, &amp;#39;__init__&amp;#39;: &amp;lt;function __main__.Employee.__init__(self, department, name)&amp;gt;, &amp;#39;inservice&amp;#39;: &amp;lt;property at 0x108419ea0&amp;gt;, &amp;#39;__repr__&amp;#39;: &amp;lt;function __main__.Employee.__repr__(self)&amp;gt;, &amp;#39;__str__&amp;#39;: &amp;lt;function __main__.Employee.__str__(self)&amp;gt;, &amp;#39;__dict__&amp;#39;: &amp;lt;attribute &amp;#39;__dict__&amp;#39; of &amp;#39;Employee&amp;#39; objects&amp;gt;, &amp;#39;__weakref__&amp;#39;: &amp;lt;attribute &amp;#39;__weakref__&amp;#39; of &amp;#39;Employee&amp;#39; objects&amp;gt;, &amp;#39;__doc__&amp;#39;: None} &amp;gt;&amp;gt;&amp;gt; type(Employee.__dict__) mappingproxy 与实例字典的『开放』不同，类属性使用的字典是一个 MappingProxyType 对象，它是一个不能 setattr 的字典。这意味着它对开发者是只读的，其目的正是为了保证类属性的键都是字符串，以简化和加快新型类属性的查找和 __mro__ 的搜索逻辑。 &amp;gt;&amp;gt;&amp;gt; Employee.__dict__[&amp;#39;outsource&amp;#39;] = False TypeError: &amp;#39;mappingproxy&amp;#39; object does not support item assignment 因为所有的方法都归属于一个类，所以它们也存储在类的字典中，从上面的例子中可以看到已有的 __init__ 和 __repr__ 方法。我们可以再添加几个来验证： class Employee: # ... @staticmethod def soo(): pass @classmethod def coo(cls): pass def foo(self): pass &amp;gt;&amp;gt;&amp;gt; Employee.__dict__ mappingproxy({&amp;#39;__module__&amp;#39;: &amp;#39;__main__&amp;#39;, &amp;#39;outsource&amp;#39;: False, &amp;#39;__init__&amp;#39;: &amp;lt;function __main__.Employee.__init__(self, department, name)&amp;gt;, &amp;#39;__repr__&amp;#39;: &amp;lt;function __main__.Employee.__repr__(self)&amp;gt;, &amp;#39;inservice&amp;#39;: &amp;lt;property at 0x108419ea0&amp;gt;, &amp;#39;soo&amp;#39;: &amp;lt;staticmethod at 0x1066ce588&amp;gt;, &amp;#39;coo&amp;#39;: &amp;lt;classmethod at 0x1066ce828&amp;gt;, &amp;#39;foo&amp;#39;: &amp;lt;function __main__.Employee.foo(self)&amp;gt;, &amp;#39;__dict__&amp;#39;: &amp;lt;attribute &amp;#39;__dict__&amp;#39; of &amp;#39;Employee&amp;#39; objects&amp;gt;, &amp;#39;__weakref__&amp;#39;: &amp;lt;attribute &amp;#39;__weakref__&amp;#39; of &amp;#39;Employee&amp;#39; objects&amp;gt;, &amp;#39;__doc__&amp;#39;: None}) 继承与属性查找 目前为止，我们已经知道，所有的属性和方法都存储在两个 __dict__ 字典中，现在我们来看看 Python 是如何进行属性查找的。 Python 3 中，所有类都隐式的继承自 object，所以总会有一个继承关系，而且 Python 是支持多继承的： &amp;gt;&amp;gt;&amp;gt; class A: ... pass ... &amp;gt;&amp;gt;&amp;gt; class B: ... pass ... &amp;gt;&amp;gt;&amp;gt; class C(B): ... pass ... &amp;gt;&amp;gt;&amp;gt; class D(A, C): ... pass ... &amp;gt;&amp;gt;&amp;gt; D.mro() [&amp;lt;class &amp;#39;__main__.D&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;__main__.A&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;__main__.C&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;__main__.B&amp;#39;&amp;gt;, &amp;lt;class &amp;#39;object&amp;#39;&amp;gt;] mro() 是一个特殊的方法，它返回类的线性解析顺序。 属性访问的默认行为是从对象的字典中获取、设置或删除属性，例如对于 e.f 的查找简单描述是: e.f 的查找顺序会从 e.__dict__[&#39;f&#39;] 开始，然后是 type(e).__dict__[&#39;f&#39;]，接下来依次查找 type(e) 的基类（__mro__ 顺序，不包括元类）。 如果找到的值是定义了某个描述器方法的对象，则 Python 可能会重载默认行为并转而发起调用描述器方法。这具体发生在优先级链的哪个环节则要根据所定义的描述器方法及其被调用的方式来决定。 所以，要理解查找的顺序，你必须要先了解描述器协议。 简单总结，有两种描述器类型：数据描述器和和非数据描述器。 如果一个对象除了定义 __get__() 之外还定义了 __set__() 或 __delete__()，则它会被视为数据描述器。仅定义了 __get__() 的描述器称为非数据描述器（它们通常被用于方法，但也可以有其他用途) 由于函数只实现 __get__，所以它们是非数据描述器。 Python 的对象属性查找顺序如下： 类和父类字典的数据描述器 实例字典 类和父类字典中的非数据描述器 请记住，无论你的类有多少个继承级别，该类对象的实例字典总是存储了所有的实例变量，这也是 super 的意义之一。 下面我们尝试用伪代码来描述查找顺序： def get_attribute(obj, name): class_definition = obj.__class__ descriptor = None for cls in class_definition.mro(): if name in cls.__dict__: descriptor = cls.__dict__[name] break if hasattr(descriptor, &amp;#39;__set__&amp;#39;): return descriptor, &amp;#39;data descriptor&amp;#39; if name in obj.__dict__: return obj.__dict__[name], &amp;#39;instance attribute&amp;#39; if descriptor is not None: return descriptor, &amp;#39;non-data descriptor&amp;#39; else: raise AttributeError &amp;gt;&amp;gt;&amp;gt; e = Employee(&amp;#39;IT&amp;#39;, &amp;#39;bobo&amp;#39;) &amp;gt;&amp;gt;&amp;gt; get_attribute(e, &amp;#39;outsource&amp;#39;) (False, &amp;#39;non-data descriptor&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e.outsource = True &amp;gt;&amp;gt;&amp;gt; get_attribute(e, &amp;#39;outsource&amp;#39;) (True, &amp;#39;instance attribute&amp;#39;) &amp;gt;&amp;gt;&amp;gt; get_attribute(e, &amp;#39;name&amp;#39;) (&amp;#39;bobo&amp;#39;, &amp;#39;instance attribute&amp;#39;) &amp;gt;&amp;gt;&amp;gt; get_attribute(e, &amp;#39;inservice&amp;#39;) (&amp;lt;property at 0x10c966d10&amp;gt;, &amp;#39;data descriptor&amp;#39;) &amp;gt;&amp;gt;&amp;gt; get_attribute(e, &amp;#39;foo&amp;#39;) (&amp;lt;function __main__.Employee.foo(self)&amp;gt;, &amp;#39;non-data descriptor&amp;#39;) 由于这样的优先级顺序，所以实例是不能重载类的数据描述器属性的，比如 property 属性： &amp;gt;&amp;gt;&amp;gt; class Manager(Employee): ... def __init__(self, *arg): ... self.inservice = True ... super().__init__(*arg) ... &amp;gt;&amp;gt;&amp;gt; m = Manager(&amp;#34;HR&amp;#34;, &amp;#34;cici&amp;#34;) AttributeError: can&amp;#39;t set attribute 发起描述器调用 上面讲到，在查找属性时，如果找到的值是定义了某个描述器方法的对象，则 Python 可能会重载默认行为并转而发起描述器方法调用。 描述器的作用就是绑定对象属性，我们假设 a 是一个实现了描述器协议的对象，对 e.a 发起描述器调用有以下几种情况： 直接调用：用户级的代码直接调用e.__get__(a)，不常用 实例绑定：绑定到一个实例，e.a 会被转换为调用: type(e).__dict__[&#39;a&#39;].__get__(e, type(e)) 类绑定：绑定到一个类，E.a 会被转换为调用: E.__dict__[&#39;a&#39;].__get__(None, E) 在继承关系中进行绑定时，会根据以上情况和 __mro__ 顺序来发起链式调用。 函数与方法 我们知道方法是属于特定类的函数，唯一的不同(如果可以算是不同的话)是方法的第一个参数往往是为类或实例对象保留的，在 Python 中，我们约定为 cls 或 self, 当然你也可以取任何名字如 this(只是最好不要这样做)。 上一节我们知道，函数实现了 __get__() 方法的对象，所以它们是非数据描述器。在 Python 访问(调用)方法支持中正是通过调用 __get__() 将调用的函数绑定成方法的。 在纯 Python 中，它的工作方式如下(示例来自描述器使用指南): class Function: def __get__(self, obj, objtype=None): if obj is None: return self return types.MethodType(self, obj) # 将函数绑定为方法 在 Python 2 中，有两种方法: unbound method 和 bound method，在 Python 3 中只有后者。 bound method 与它们绑定的类或实例数据相关联： &amp;gt;&amp;gt;&amp;gt; Employee.coo &amp;lt;bound method Employee.coo of &amp;lt;class &amp;#39;__main__.Employee&amp;#39;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; Employee.foo &amp;lt;function __main__.Employee.foo(self)&amp;gt; &amp;gt;&amp;gt;&amp;gt; e = Employee(&amp;#39;IT&amp;#39;, &amp;#39;bobo&amp;#39;) &amp;gt;&amp;gt;&amp;gt; e.foo &amp;lt;bound method Employee.foo of &amp;lt;Employee: IT-bobo&amp;gt;&amp;gt; 我们可以从方法来访问实例与类： &amp;gt;&amp;gt;&amp;gt; e.foo.__self__ &amp;lt;Employee: IT-bobo&amp;gt; &amp;gt;&amp;gt;&amp;gt; e.foo.__self__.__class__ __main__.Employee 借助描述符协议，我们可以在类的外部作用域手动绑定一个函数到方法，以访问类或实例中的数据，我将以这个示例来解释当你的对象访问(调用)类字典中存储的函数时将其绑定成方法(执行)的过程： 现有以下函数： &amp;gt;&amp;gt;&amp;gt; def f1(self): ... if isinstance(self, type): ... return self.outsource ... return self.name ... &amp;gt;&amp;gt;&amp;gt; bound_f1 = f1.__get__(e, Employee) # or bound_f1 = f1.__get__(e) &amp;gt;&amp;gt;&amp;gt; bound_f1 &amp;lt;bound method f1 of &amp;lt;Employee: IT-bobo&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; bound_f1.__self__ &amp;lt;Employee: IT-bobo&amp;gt; &amp;gt;&amp;gt;&amp;gt; bound_f1() &amp;#39;bobo&amp;#39; 总结一下：当我们调用 e.foo() 时，首先从 Employee.__dict__[&#39;foo&#39;] 中得到 foo 函数，在调用该函数的 foo 方法 foo.__get__(e) 将其转换成方法，然后执行 foo() 获得结果。这就完成了 e.foo() -&amp;gt; f(e) 的过程。 如果你对我的解释感到疑惑，我建议你可以阅读官方的描述器使用指南以进一步了解描述器协议，在该文的函数和方法和静态方法和类方法一节中详细了解函数绑定为方法的过程。同时在 Python 类一文的方法对象一节中也有相关的解释。 __slots__ Python 的对象属性值都是采用字典存储的，当我们处理数成千上万甚至更多的实例时，内存消耗可能是一个问题，因为字典哈希表的实现，总是为每个实例创建了大量的内存。所以 Python 提供了一种 __slots__ 的方式来禁用实例使用 __dict__，以优化此问题。 通过 __slots__ 来指定属性后，会将属性的存储从实例的 __dict__ 改为类的 __dict__ 中： class Test: __slots__ = (&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;) def __init__(self, a, b): self.a = a self.b = b &amp;gt;&amp;gt;&amp;gt; t = Test(1, 2) &amp;gt;&amp;gt;&amp;gt; t.__dict__ AttributeError: &amp;#39;Test&amp;#39; object has no attribute &amp;#39;__dict__&amp;#39; &amp;gt;&amp;gt;&amp;gt; Test.__dict__ mappingproxy({&amp;#39;__module__&amp;#39;: &amp;#39;__main__&amp;#39;, &amp;#39;__slots__&amp;#39;: (&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;), &amp;#39;__init__&amp;#39;: &amp;lt;function __main__.Test.__init__(self, a, b)&amp;gt;, &amp;#39;a&amp;#39;: &amp;lt;member &amp;#39;a&amp;#39; of &amp;#39;Test&amp;#39; objects&amp;gt;, &amp;#39;b&amp;#39;: &amp;lt;member &amp;#39;b&amp;#39; of &amp;#39;Test&amp;#39; objects&amp;gt;, &amp;#39;__doc__&amp;#39;: None}) 关于 __slots__ 我之前专门写过一篇文章分享过，感兴趣的同学请移步理解 Python 类属性 __slots__ 一文。 补充 __getattribute__ 和 __getattr__ 也许你还有疑问，那函数的 __get__ 方法是怎么被调用的呢，这中间过程是什么样的？ 在 Python 中 一切皆对象，所有对象都有一个默认的方法 __getattribute__(self, name)。 该方法会在我们使用 . 访问 obj 的属性时会自动调用，为了防止递归调用，它总是实现为从基类 object 中获取 object.__getattribute__(self, name), 该方法大部分情况下会默认从 self 的 __dict__ 字典中查找 name(除了特殊方法的查找)。 话外：如果该类还实现了 __getattr__，则只有 __getattribute__ 显式地调用或是引发了 AttributeError 异常后才会被调用。__getattr__ 由开发者自己实现，应当返回属性值或引发 AttributeError 异常。 而描述器正是由 __getattribute__() 方法调用，其大致逻辑为： def __getattribute__(self, key): v = object.__getattribute__(self, key) if hasattr(v, &amp;#39;__get__&amp;#39;): return v.__get__(self) return v 请注意：重写 __getattribute__() 会阻止描述器的自动调用。 函数属性 函数也是 Python function 对象，所以一样，它也具有任意属性，这有时候是有用的，比如实现一个简单的函数调用跟踪装饰器： def calltracker(func): @wraps(func) def wrapper(*args, **kwargs): wrapper.calls += 1 return func(*args, **kwargs) wrapper.calls = 0 return wrapper @calltracker def f(): return &amp;#39;f called&amp;#39; &amp;gt;&amp;gt;&amp;gt; f.calls 0 &amp;gt;&amp;gt;&amp;gt; f() &amp;#39;f called&amp;#39; &amp;gt;&amp;gt;&amp;gt; f.calls 1 参考 HowFunctionsToMethods Descriptor HowTo Guide Python Data model Understanding internals of Python classes</description>
    </item>
    
    <item>
      <title>GC 机制探究之 Python 篇</title>
      <link>https://at7h.com/posts/gc-in-py/</link>
      <pubDate>Tue, 08 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/gc-in-py/</guid>
      <description>本文主要讨论垃圾回收（Garbage Collection）机制在 Python 3.7 中是如何工作的。 不同的 Python 解释器有各自 GC 的实现方式，比如 Jython 跑在 JVM 上，采用了标准的 Java GC，Pypy 的 GC 使用了标记-清除(Mark and Sweep)算法，它比 CPython 的更加复杂并且有着一些额外的优化。 本文讨论主流的 CPython 解释器。 通常，你在使用一些高级语言（Python、Golang、Java 等）编写代码的时候，一般无需关心内存管理的问题，当对象不再需要的时候，GC 会自动的把它们回收。但是了解 GC 的工作原理可以帮助你编写更好、更快的程序，帮助你排查一些复杂的内存问题。 常见 GC 算法 业界常见的比较知名的垃圾回收算法有： 1. 引用计数(Reference counting)：对每个对象维护一个引用计数，当引用计数器为零时回收该对象。代表语言如 Python。 优点：简单有效，对象可以被很快回收，不会出现内存耗尽或达到某个阀值时才回收。 缺点：很明显，对每个对象维护引用计数有一定代价，而且致命的是无法处理循环引用的问题。 2. 标记-清除(Mark and Sweep)：为解决循环引用问题而提出，算法从根对象开始遍历程序所有对象的引用，可达的对象被标记，最终没被标记的对象被删除回收。代表语言如 Golang(三色标记)。 优点：解决循环引用的问题，并且在算法执行期间不会产生额外的开销。 缺点：需要 STW(stop the world)，即执行期间需要程序暂停，并且容易在经过多次『标记-清除』循环后导致内存碎片化。 3. 停止-复制(Stop-and-Copy) ：与标记-清除算法类似，差异在于如何处理这些可达的存活对象。该算法将整个堆空间被切分活动区和空闲区，垃圾收集时将所有的可达的存活对象复制到另一区，原本半区的就可以被回收，程序会在新的活动区中分配内存。 优点：运行高效且不容易产生内存碎片，基本解决了标记-清除内存碎片化的问题。 缺点：需要 STW，收集器必须复制所有的活动对象，这增加了程序等待时间，并且在同一时间内只能使用整个内存空间的一半。 3. 标记-压缩(Mark-and-Compact) ：标记阶段与标记-清除算法相同，压缩（整理）阶段不是直接清理，而是让所有的对象都向一端移动，按顺序排放更新对应的指针，然后清理掉端边界以外的内存。 优点：避免了标记-清除的碎片化问题，同时也避免了停止复制算法的内存空间减半问题。 缺点：需要 STW，低效，因为增加了 copy 和更新指针的过程。 5. 分代收集(Generational Collection)：与其说是一种新算法不如说是一种优化策略，目前很流行。算法按照对象生命周期长短划分不同的代空间，生命周期长的放入老年代，短的放入新生代，从而区别不同的回收算法策略和频率，让各算法充分发挥优势。代表语言如 Java。 优点：可结合其他检测算法，回收性能好。 缺点：算法比较复杂。 没有绝对好和坏的解决方案，在真正语言实现中一般都是几种算法结合使用，下面主要来探讨 Python 中的垃圾回收策略。 GC in Python 在 Python 中，一切皆对象，知道它们什么时候被分配内存很容易，当你需要的时候你可以很容易创建一个新的对象。但回收确是比较复杂的一件事，需要确定你的对象确实是不再需要了，过早的清理可能会导致程序崩溃，如果不予以释放，则会造成内存泄露。 垃圾回收的主要任务就是确定哪些对象可以被收回，并选择一个最佳的时间来释放它们占用的内存。标准的 CPython GC 有两个组件： 引用计数收集器(reference counting collector)：主要的、基础模块、不可控，不能禁用。 分代垃圾收集器(generational garbage collector)：辅助的、可以控制，即 gc module。 CPython 的垃圾回收主要是通过引用计数技术，引用计数是非常有效和简单的，但它不能检测循环引用(reference cycles)，因此 CPython 又设计了一个分代垃圾收集器作为补充算法来专门处理循环引用的问题.因它只处理循环引用，也被称为分代循环(generational cyclic) GC。Python 中常说的 GC 其实就是它，其默认情况下是启用的，你可以手动触发和禁用它。 CPython GC 的策略是： 对每个对象维护引用计数 通过一个辅助算法来定期检测循环引用，释放无用对象 引入分代策略来优化此检测，提高性能 引用计数 引用计数是一种简单的技术，当程序中没有对该对象的引用时，将其释放。 Python 中的每个变量都是对真实对象的引用（指针），为了跟踪引用，每个对象（包括整数、字符串）都会有一个引用计数的额外字段，该字段会一直维护，在创建或删除指向该对象的引用时会增加或减少。有关详细说明，可以参见 Objects, Types and Reference Counts 部分。 导致引用计数增加主要有： 赋值运算符 参数传递 将对象（作为元素）append 到容器中 如果对象的引用计数达到零，CPython 会自动调用对象特定的内存释放函数。如果一个对象包含对其他对象的引用，则它们的引用计数也会自动减少，因此，可以依次释放其他对象。例如，当删除 List 时，所有 List 元素的引用计数都会减少。如果存在另一个变量引用了 List 中的某个项目，则该元素不会被释放。 在 Python 中，全局变量会一直存在直到 Python 进程结束为止。因此，由全局变量引用的对象的引用计数永远不会降为零，所有全局变量都存储在字典中，你可以通过调用 globals() 函数来获取它们。 在某一个『块』中定义的局部变量，如 function、class 或 with（context&amp;rsquo;s enter/exit) 语句具有局部作用域，当解释器从该块中退出时，会释放在该块内部创建的局部变量及其引用。在 Python 中，用的最多的『块』应该就是函数（方法）了，这是大多数垃圾收集发生的地方，同时这也是保持函数功能单一一个原因吧。 在 Python 中，你始终可以使用 sys.getrefcount 函数检查对象引用的数量。来看一个简单的示例： In [1]: import sys In [2]: sys.getrefcount? Docstring: getrefcount(object) -&amp;gt; integer Return the reference count of object. The count returned is generally one higher than you might expect, because it includes the (temporary) reference as an argument to getrefcount(). Type: builtin_function_or_method In [3]: l = [] In [4]: sys.getrefcount(l) Out[4]: 2 # 变量 l 和 getrefcount 中的临时变量 In [5]: def f(a): ...: print(&amp;#34;Here reference count is:&amp;#34;, sys.getrefcount(a)) ...: In [6]: f(l) Here reference count is: 4 In [7]: sys.getrefcount(l) Out[7]: 2 # 函数作用域的被销毁 有时我们需要刻意的手动删除某一变量，可以使用 del 语句（其删除变量及其引用，而不是对象本身），这在 REPL 环境（Jupyter notebooks，IPython 等）工作时通常很有用，因为所有变量都是全局范围的。 个人觉得，CPython 使用引用计数主要是历史原因，关于这种技术的弱点很多争论。很多人觉得现代垃圾收集算法可以更高效，无需引用计数，引用计数算法有很多问题，例如循环引用，线程锁定以及内存和性能的额外开销。 引用计数应该也是 CPython 无法摆脱 GIL 的原因之一。 循环引用 以下情况会产生循环引用： 对象包含本身的引用 两个对象之间相互引用 为了证明这一点，我们使用 ctypes 模块来跟踪访问对象的内存地址，以展示上面两种情况： In [1]: import gc, ctypes In [2]: gc.disable() In [3]: class Object(ctypes.Structure): ...: _fields_ = [(&amp;#34;refcnt&amp;#34;, ctypes.c_long)] In [4]: l = [] ...: l.append(l) In [5]: lst_address = id(l) In [6]: del l In [7]: object_1 = {} ...: object_2 = {} ...: object_1[&amp;#39;obj2&amp;#39;] = object_2 ...: object_2[&amp;#39;obj1&amp;#39;] = object_1 In [8]: obj_address = id(object_1) In [9]: del object_1, object_2 In [10]: Object.from_address(obj_address).refcnt Out[10]: 1 In [11]: Object.from_address(lst_address).refcnt Out[11]: 1 示例中，del 语句删除了对象的引用，对象被 del 后，我们不能再从 Python 代码中访问这些对象，但它们仍位于内存中。在 Python 2.0 版本以前，它们在程序运行中永远不会被释放。发生这种情况就是因为它们仍然相互引用，并且每个对象的引用计数为 1，感兴趣的同学你可以使用 objgraph 模块来直观地探索这种对象关系。 解决循环引用问题 为了解决循环引用问题，CPython 引入了一种附加的循环引用检测算法来负责处理这样的问题（即自 Python 2.0 开始的 gc 模块）。 那么问题来了，为什么当时不采用上文说的几种传统回收算法（如 Mark and Sweep 或 Stop-and-Copy 等）呢？原因是由于 CPython 扩展模块的工作方式，CPython 永远无法完全确定根集，这样就有可能释放仍然在某个地方有引用的对象，造成程序崩溃。所以最终是在引用计数的基础上，设计了一种可以检测并处理循环引用的算法。 提示：如果你使用搜索引擎搜索过相关的文章，你可能会发现很多文章都讲『Python 是以引用计数为主，标记-清除和分代收集为辅的』收集策略，这是错误的，CPython 中使用的循环引用检测算法（下一节中介绍）并不是标记-清除。使用标记-清除算法的是 Pypy 的 GC。 从概念来说，CPython GC 与上述的几种算法刚好相反，它试图找出不可达的非活动对象，CPython 的开发者认为这将更加安全，即使算法失败，状况也不会比没有垃圾回收的情况更糟（除了浪费的时间和空间）。（就是感觉并不是那么自信 😂 因为循环引用只会在容器类对象中发生，所以只需专注于跟踪所有的容器对象，而且，某些情况下的的容器对象也是不会产生循环引用的（例如只包含不可变对象的字典），所以对于这一类的对象可以进行取消跟踪的优化，取消跟踪一般会在以下两个时机进行： 创建容器对象时 容器对象被收集器检查时 CPython GC 检测算法不会跟踪除元组以外的所有不可变类型，并且作为优化策略，只包含不可变对象的元组和字典也在某些条件下被取消跟踪（其中元组对象是在 GC 过程中决定是否继续跟踪，而字典对象会在创建和 GC 过程中决定）。 我们可以使用 gc.is_tracked(obj) 函数来查看对象的跟踪状态。看几个例子： In [1]: import gc In [2]: gc.is_tracked(1) Out[2]: False In [3]: gc.is_tracked(&amp;#39;s&amp;#39;) Out[3]: False In [4]: gc.is_tracked([]) Out[4]: True In [5]: gc.is_tracked({}) Out[5]: False In [6]: gc.is_tracked({&amp;#39;s1&amp;#39;: 1}) Out[6]: False In [7]: gc.is_tracked({&amp;#39;s1&amp;#39;: []}) Out[7]: True 再来看一个对于字典和元组对象优化的例子: In [8]: d = {&amp;#39;s&amp;#39;: 1} In [9]: gc.is_tracked(d) Out[9]: False In [10]: d[&amp;#39;l&amp;#39;] = [] In [11]: gc.is_tracked(d) Out[11]: True In [12]: t = (1,2,3) In [13]: gc.is_tracked(t) Out[13]: True In [14]: gc.collect() Out[14]: 1015 In [15]: gc.is_tracked(t) Out[15]: False 如何找到循环引用？ 关于 CPython GC 检测循环引用的具体算法逻辑，很难用几段话解释。其主要是维护了两个双向链表，一个包含所有要扫描的对象，另一个包含『暂时』无法访问的所有对象。每个跟踪的容器的对象都有额外的 2+1 个字段，即两个链表指针和一个 gc_refs 字段（初始值为该对象的引用数）。然后寻找循环引用的大致思路是，遍历所有要扫描的容器对象，对于每个容器对象，找到它引用的所有容器对象，并减小其 gc_refs 值，经过完全迭代后，所有引用计数小于 2 的对象都再无法从 Python 访问，因此可以将其收集。 为了完全理解循环引用查找算法，建议感兴趣的同学继续阅读 dentifying reference cycles 一节，或从 CPython 的源码中查看 collect 函数。 使用分代策略优化 CPython GC 有了上述循环引用检测算法，已经可以检测并处理掉程序中循环引用的对象了。接下来就需要关心性能问题了，因为它是定期运行的，所以 CPython 的开发者为此也引入了启发式的分代策略。 为了使收集花费的时间尽可能短 ，CPython GC 将容器对象分为三代，每个新建的对象都归于最年轻第一代，如果该对象在一次垃圾收集中幸存下来，没有被释放，那么它将被移至较高(老)的一代——第二代。与高(老)世代相比，较低(年轻)世代的垃圾收集频率更高，所以大多数临时对象(局部变量等)的创建和清理都是很快的，由此提高了 GC 的性能减少了 GC 的暂停时间。 为了决定何时执行 GC，每个世代都有一个单独的计数器和阈值，计数器存储当代自上次垃圾收集以来分配对象数量减去被释放对象数量的差值，这得益于算法对容器对象的跟踪。每当你分配一个新的容器对象时，CPython 都会检查第一代计数器的值是否超过阈值。如果超过阈值，则在第一代中启动一次 GC(运行上述算法)，那些不会被使用的对象将会被释放，其余被移至第二代，更新计数器，以此类推。 当前各代的计数器值可以通过 gc.get_count() 查看。标准阈值内置为(700, 10, 10)，你可以使用 gc.get_threshold() 查看, 还可以使用 gc.get_threshold 函数进行调整。 此外，你还可以通过 gc.collect(generation=None) 手动触发 GC。 如果你有兴趣，可以继续在 CPython 的源码中查看 collect 函数，以了解更加具体的算法逻辑。 总结 CPython 的大部分垃圾收集是通过引用计数完成的，我们无法对其进行干涉调整，通过辅助的分代 GC 来处理循环引用，其可控，即 gc module。关于性能： 所有对象(包括数字、字符串)都必须实时正确的维护引用计数，这需要额外的内存与 CPU 开销，另外维护容器对象的跟踪字段(也需要额外的内存和 CPU 开销。 WTP 时间其他实现相比相对较少，这得益于引用计数策略(只要没有太多的循环引用)，CPython 并没有对此进行特殊优化，如 Golang 的写屏障(Write Barrier)等。 CPython GC 并没有将所有活动的可达对象拷贝到另一整块内存重新编排，所以还是会造成内存碎片。 提示或建议 1. 如果你可以保证不会出现循环引用，则可以通过 gc.disable 完全禁用 GC，在某些情况下，禁用 GC 并手动 gc.collect() 很有用。 2. 为避免产生循环引用，可考虑使用弱引用 weakref ，weakref.ref 不会增加引用计数，并且当对象只剩弱引用时不会保持其活性（可以被 GC 正常回收），并在对象被释放后安全返回 None。 3. 循环在现实生活中很容易发生。通常，您会在图形，链接列表或结构中遇到它们，在其中需要跟踪对象之间的关系。如果您的程序工作量大且要求低延迟，则需要尽可能避免参考周期。 查找或调试分析循环引用 1. 标准 gc 模块 提供了接口可以帮助调试，例如 gc.set_debug(gc.DEBUG_SAVEALL)，则找到的所有的不可达对象将追加到 gc.garbage 列表中，你可以在其中查看。 2. 当你发现了循环引用的对象后，就可以使用上文中提到的 objgraph 来直观的探索它与其它对象间的关系。 参考 Design of CPython’s Garbage Collector Garbage collection in Python: things you need to know Garbage Collection for Python How does garbage collection in Python work? What are the pros and cons?</description>
    </item>
    
    <item>
      <title>Helo 快速上手指南</title>
      <link>https://at7h.com/posts/helo/</link>
      <pubDate>Tue, 18 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/helo/</guid>
      <description>其中，u.update(name=&amp;quot;Daisy&amp;rdquo;) 与 u.name = &amp;ldquo;Daisy&amp;rdquo; 类似，都是只在内存里修改对象的属性，不同的是 u.update() 还会返回一个包含本次变更的中间结果，对其执行 await xxx.apply() 则会将这些变更应用到数据库里。 Helo 是本人业余开发的一个简单小型低级别的异步(asyncio) Python ORM。它几乎没有什么概念，非常直白，容易上手使用。 此处去往项目仓库 ，欢迎使用、提出意见或贡献代码 😊 Helo 可以在你的异步应用中帮助你轻松的构建出富有表达力的常用 SQL 语句，你只需以友好的对象化 API 来操作数据，而不用关心 SQL 语句编写、数据处理等细节。 请注意：使用异步 ORM 并不完全意味着可以使你的应用变快，而且有可能会使你的应用变得复杂。继续之前，你可以先阅读下 SQLAlchemy 作者 Mike Bayer 的 这篇博客文章。 本篇上手指南主要介绍以下方面: 安装 helo 模型声明 建立连接 数据操作 在 quart 应用中使用 helo 其他补充 开始使用 安装 helo 可以通过以下两种方式: 1. 安装 pypi 的稳定发布版本, 在终端中运行此命令: $ pip install helo 2. 从最新的源码安装 $ git clone https://github.com/at7h/helo.git $ cd helo $ python setup.py install 安装完成后就开始下面的入坑之旅了 😈 。 使用 helo, 首先你需要引入 helo 并使用 helo.G 实例化一个全局变量，假定称其为 db: import helo db = helo.G() db 是一个全局单例对象，下面的介绍中我们将多次使用到它。 模型声明 使用 helo 声明模型很简单，只需从 helo.Model 继承即可。下面给出几个模型声明的简单的例子： class Person(helo.Model): id = helo.BigAuto() name = helo.VarChar(length=45, null=False) class User(Person): email = helo.Email(default=&amp;#39;&amp;#39;) password = helo.VarChar(length=100, null=False) create_at = helo.Timestamp(default=helo.ON_CREATE) class Meta: indexes = [helo.K(&amp;#39;idx_ep&amp;#39;, [&amp;#39;email&amp;#39;, &amp;#39;password&amp;#39;])] class Employee(Person): department = helo.Smallint() salary = helo.Float(default=0) class Post(helo.Model): id = helo.Auto(comment=&amp;#39;auto increment pk&amp;#39;) title = helo.VarChar(length=100) content = helo.Text(encoding=helo.ENCODING.UTF8MB4) author = helo.Int(default=0) create_at = helo.Timestamp(default=helo.ON_CREATE) update_at = helo.Timestamp(default=helo.ON_UPDATE) class Meta: indexes = [ helo.K(&amp;#39;idx_title&amp;#39;, &amp;#39;title&amp;#39;), helo.K(&amp;#39;idx_author&amp;#39;, &amp;#39;author&amp;#39;), ] 内部类 Meta 可用于指定 db_name, table_name, engine, indexes, charset, comment 等 Table 的元属性。 class Meta: db = &amp;#39;db_name&amp;#39; name = &amp;#39;table_name&amp;#39; engine = helo.ENGINE.innodb charset = helo.ENCODING.utf8mb4 indexes = [] comment = &amp;#39;table comment&amp;#39; 其中 table_name 默认为 model 类名的 snake_case 风格名称，engine 默认为 InnoDB，charset 默认为 utf8mb4。 建立连接 前面的模型声明只是定义了模型与真实表结构的映射关系，并非实际在数据库中创建了这些表结构。为此，我们需要先使用 helo 来与数据库建立连接，这里我们创建一个 MySQL 的数据库实例： &amp;gt;&amp;gt;&amp;gt; await db.bind(&amp;#39;mysql://user:pwd@localhost:3306/helo&amp;#39;) 或者传递配置参数： &amp;gt;&amp;gt;&amp;gt; await db.bind(user=&amp;#39;user&amp;#39;, password=&amp;#39;pwd&amp;#39;, db=&amp;#39;helo&amp;#39;) 如果你设置了环境变量 HELO_DATABASE_URL，那么你不用再传递 url: &amp;gt;&amp;gt;&amp;gt; await db.bind() 如果你想自定义 KEY 的值，可以在初始化 db 时通过 env_key 参数来设置: db = helo.G(env_key=&amp;quot;YOUR_ENV_KEY&amp;quot;) bind 实际上为我们创建了一个数据库连接池： &amp;gt;&amp;gt;&amp;gt; db.state {&amp;#39;minsize&amp;#39;: 1, &amp;#39;maxsize&amp;#39;: 15, &amp;#39;size&amp;#39;: 1, &amp;#39;freesize&amp;#39;: 1} bind 给我们提供了很多关键字参数来允许我们自定义设置，详见 helo.db.Pool 类。例如： &amp;gt;&amp;gt;&amp;gt; await db.bind(&amp;#39;mysql://user:pwd@127.0.0.1:3306/db&amp;#39;, maxsize=10, connect_timeout=15) 已经创建的连接池对象将是一个全局的单例对象，也就是说如果你已经为你的应用程序调用 bind 绑定了数据库，在此之前如果你没有使用 unbind 进行解绑，你将不能再继续使用 bind 再次绑定另一个数据库，否则你将会得到一个 helo.err.DuplicateBinding 错误。 如果你需要显式地断开与数据库的连接，关闭连接池，可以使用 unbind: &amp;gt;&amp;gt;&amp;gt; await db.unbind() 在小型的脚本中你可以使用 db.binder 来自动处理上下文： &amp;gt;&amp;gt;&amp;gt; async with db.binder(): ... pass 数据操作 与数据库建立了连接之后，我们需要在数据库创建我们的表，以便于接下来进行数据的操作。 在真正的应用中，数据库表的设计创建与维护是单独分开，一般由专门的 DBA 来管理。当然 helo 也提供了基础的 DDL 支持。 下面我们在数据库创建它们： &amp;gt;&amp;gt;&amp;gt; await db.create_tables([User, Employee, Post]) 在应用项目中，我们通常将所有的模型声明单独放在一个模块中，在此假设模块名为 models，则可以使用 create_all 为模块中所有的 model 创建表： &amp;gt;&amp;gt;&amp;gt; from your.application import models &amp;gt;&amp;gt;&amp;gt; await db.create_all(models) 当然你也可以使用 Model 的方法来单独创建: &amp;gt;&amp;gt;&amp;gt; await User.create() Helo 提供了基本的操作数据库中数据的能力，支持丰富的可组合的逻辑运算表达，你可以轻松的完成富有表达力的 queries，以实现通过对象化的 API 来构建你想要的 SQL 语句(DML 和 DQL)的能力。 下面示例基本的增删改查的操作。 增 使用 helo 你可以有多种插入数据的方式选择，我们从创建一个 User 对象开始: user = User(name=&amp;#39;at7h&amp;#39;, password=&amp;#39;1111&amp;#39;) print(user.name, user.password) # at7h, 1111 # Now user.id is None, because it is not saved to the database assert user.id is None 此时的 user 仅是内存中的一个对象，你需要通过 save 方法持久化到数据库中： user_id = await user.save() assert user_id == user.id == 1 我们可以修改它，并保存更改： user.name = &amp;#39;at8h&amp;#39; user.email = &amp;#39;g@at7h.com&amp;#39; user_id = await user.save() assert user_id == user.id == 1 请注意： 目前 save 操作是通过 MySQL REPLACE 语句实现，其根据对象的 PRIMARY KEY 属性或 UNIQUE KEY 属性的值来决定是否插入新行，请谨慎使用！该实现计划在后续版本中优化。 推荐使用下面几种方式来插入数据。 方法 add, madd 可以用来添加单条或多条数据，它们是 insert, minsert 的简单快捷方式： user_id = await User.add(name=&amp;#39;bobo&amp;#39;, password=&amp;#39;2222&amp;#39;) # Or: user_id = await User.add({&amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;, &amp;#39;password&amp;#39;: &amp;#39;2222&amp;#39;}) print(user_id) # 2 users = [{&amp;#39;name&amp;#39;: &amp;#39;mingz&amp;#39;, &amp;#39;password&amp;#39;: &amp;#39;3333&amp;#39;}, {&amp;#39;name&amp;#39;: &amp;#39;xy69z&amp;#39;, &amp;#39;password&amp;#39;: &amp;#39;4444&amp;#39;}] # Or using user object list: # users = [User(name=&amp;#39;mingz&amp;#39;, password=&amp;#39;3333&amp;#39;), # User(name=&amp;#39;xy69z&amp;#39;, password=&amp;#39;4444&amp;#39;)] count = await User.madd(users) print(count) # 2 方法 insert 和 minsert 是最正确的数据插入姿势，它们可以胜任多种数据形式，它们将返回一个 Insert 对象，要执行此操作，请不要忘了写 do() 哦 😉： ret = await User.insert(name=&amp;#39;poper&amp;#39;, password=&amp;#39;5555&amp;#39;).do() # Or: ret = await User.insert({&amp;#39;name&amp;#39;: &amp;#39;bingo&amp;#39;, &amp;#39;password&amp;#39;: &amp;#39;8888&amp;#39;}).do() assert ret.affected == 1 assert ret.last_id == 5 print(ret) # (1, 5) # Inserting multiple employees = [ {&amp;#39;name&amp;#39;: &amp;#39;at7h&amp;#39;, &amp;#39;department&amp;#39;: 1}, {&amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;, &amp;#39;department&amp;#39;: 2}, ] ret = await Employee.minsert(employees).do() print(ret) # (2, 1) # Specify row tuples columns the tuple values correspond to posts = [ (&amp;#39;post1&amp;#39;, 1), (&amp;#39;post2&amp;#39;, 2), ] ret = await Post.minsert( posts, columns=[Post.title, Post.author] ).do() print(ret) # (2, 1) 使用 insert_from 支持表间数据填充： select = User.select(User.name).where(User.id.in_([3, 4, 5])) ret = await Employee.insert_from(select, [Employee.name]).do() print(ret) # (3, 3) 查 Helo 也有多种获取数据的方式选择，如简单获取单条数据可以使用 get 方法： # By id user = await User.get(1) assert isinstance(user, User) print(user.id, user.name, user.password) # 1, at7h, 1111 # Or by query assert (await User.get(User.name == user.name)) == user 获取多条数据可以使用 mget 方法： # By id list uid_list = [1, 2, 3] users = await User.mget(uid_list) print(users.count) # 3 print(users) # [&amp;lt;User object at 1&amp;gt;, &amp;lt;User object at 2&amp;gt;, &amp;lt;User object at 3&amp;gt;] # Specify columns users = await User.mget(uid_list, columns=[User.id, User.name]) assert users[0].password is None # Or by query users = await User.mget((User.id &amp;lt; 2) | (User.name == &amp;#39;mingz&amp;#39;)) print(users) # [&amp;lt;User object at 1&amp;gt;, &amp;lt;User object at 3&amp;gt;] 同样的，方法 get 和 mget 也是 select 的简单快捷版本，其只适合于已知主键或查询条件比较简单的场景，更多的时候我们还是需要使用 select。 使用 select 方法可以帮助你以对象化 API 的方式轻松的构造你的 DQL，其支持丰富的可组合的逻辑条件表达式。 users = await User.select().order_by( User.id.desc() ).limit(3).offset(2).all() print(users) # [&amp;lt;User object at 5&amp;gt;, &amp;lt;User object at 4&amp;gt;, &amp;lt;User object at 3&amp;gt;] 方法 all() 以及下面提到的 get(), first(), rows(), paginate() 等方法类似于上面提到的 do()，都用于驱动执行此次查询，不要忘了哦。 比如我需要知道有没有使用 gmail 邮箱的用户： is_exist = await User.select().where( User.email.endswith(&amp;#39;gmail.com&amp;#39;) ).exist() print(is_exist) # False 比如我想知道 2019 年 7 月以来共新增了多少用户： user_count = await User.select().where( User.create_at &amp;gt; datetime(2019, 7, 1) ).count() print(user_count) # 4 再比如我们需要分页的获取今年写了 Python(title) 相关文章的用户： users = await User.select().where( User.id.in_( Post.select(Post.author).where( Post.update_at &amp;gt; datetime(2019, 1, 1), Post.title.contains(&amp;#39;Python&amp;#39;) ).order_by( Post.update_at.desc() ) ) ).paginate(1, 10) print(users) # [&amp;lt;User object at 1&amp;gt;] 再比如我们想知道每个用户都写了多少篇文章： user_posts = await User.select( User.name, helo.F.COUNT(helo.SQL(&amp;#39;1&amp;#39;)).as_(&amp;#39;posts&amp;#39;) ).join( Post, helo.JOINTYPE.LEFT, on=(User.id == Post.author) ).group_by( User.name ).rows(100) print(user_posts) # [{&amp;#39;name&amp;#39;: &amp;#39;at7h&amp;#39;, &amp;#39;posts&amp;#39;: 1}] 如上所示，我们可以通过 helo.F 来使用 SQL 函数，比如我需要计算出每个月所有雇员薪资的总和： salary_sum = await Employee.select( helo.F.SUM(Employee.salary).as_(&amp;#39;salary_sum&amp;#39;) ).scalar() print(salary_sum) # 30000.0 改 接下来，让我们尝试对数据库中的数据做一些修改操作。 比如你要更改某一位雇员的薪资 😋： ret = await Employee.update(salary=20000).where( Employee.name == &amp;#39;at7h&amp;#39; ).do() print(ret.affected) # 1 或者，整体涨工资啦 👏： ret = await Employee.update( salary=Employee.salary + 1000 ).where( (Employee.department.in_([1, 2])) | (Employee.name == &amp;#39;at7h&amp;#39;) ).do() 删 最后我们来尝试删除表中的数据。 第一种方式，你可以使用 model 对象的 remove 方法来删除它对应于数据库中这一行的数据： user = User(name=&amp;#39;at7h&amp;#39;, password=&amp;#39;1111&amp;#39;) await user.save() user = await User.get(user_id) print(user.id) # 1 await user.remove() user = await User.get(user_id) print(user) # None 另一种更为通常的方式是使用 delete 方法： ret = await Post.delete().where( Post.create_at &amp;lt; datetime(2010, 1, 1) ).limit( 100 ).do() 请注意： 永远不要忘记写 where 子句，是不是整个表都不想要了 😟 ？ Replace 另外，helo 支持 MySQL REPLACE 语句，提供了 replace 和 mreplace 两个方法，其用法与 insert 和 minsert 类似。当然，在使用它们之前你需要了解 MySQL REPLACE 语句的工作原理。 Quart 应用 如果你正在使用 quart, 一个最小的应用示例是: import quart import helo app = quart.Quart(__name__) app.config[&amp;#34;HELO_DATABASE_URL&amp;#34;] = &amp;#34;mysql://user:password@127.0.0.1:3306/db&amp;#34; db = helo.G(app) @app.route(&amp;#39;/api/users&amp;#39;) async def users(): await User.insert( name=&amp;#39;at7h&amp;#39;, email=&amp;#39;g@test.com&amp;#39;, password=&amp;#39;xxxx&amp;#39; ).do() user_list = await User.select().all(False) return quart.jsonify(user_list) app.run() 此时你不需要再显示的执行 db.bind，binding 操作将会在你应用的第一个请求之前自动完成。 启动此服务: $ curl http://127.0.0.1:5000/api/users [{&amp;#34;email&amp;#34;:&amp;#34;g@test.com&amp;#34;,&amp;#34;id&amp;#34;:1,&amp;#34;name&amp;#34;:&amp;#34;at7h&amp;#34;,&amp;#34;password&amp;#34;:&amp;#34;xxxx&amp;#34;}] 其他 Model Iteration Helo 中的 Model 和 Select 都支持迭代，helo 会自动帮你处理分页问题，以避免频繁的 IO 操作和过大的数据量获取。 async for post in Post: print(post) # &amp;lt;Post object at 1&amp;gt; # &amp;lt;Post object at 2&amp;gt; # &amp;lt;Post object at 3&amp;gt; # &amp;lt;Post object at 4&amp;gt; users = User.select().where(User.id &amp;lt; 5).order_by(User.id.desc()) async for user in users: print(user) # &amp;lt;User object at 4&amp;gt; # &amp;lt;User object at 3&amp;gt; # &amp;lt;User object at 2&amp;gt; # &amp;lt;User object at 1&amp;gt; Row Type 当你使用 select 获取数据时，helo 默认会将行数据包装成为对应的 Model 对象，但是，当你使用了 helo.F 函数和 join 时可能会放弃加载到 Model 对象而使用原始的 helo.adict 字典。当然，你也可以通过 wrap 参数来显式指定使用字典类型的 row type。在大型项目中，这可能会显著提高速度并减少内存的使用。 users = await User.select(User.id, User.name).limit(2).all(wrap=False) print(users) # [{&amp;#39;id&amp;#39;: 1, &amp;#39;name&amp;#39;: &amp;#39;at7h&amp;#39;}, {&amp;#39;id&amp;#39;: 2, &amp;#39;name&amp;#39;: &amp;#39;bobo&amp;#39;}] assert users[0].name == &amp;#39;at7h&amp;#39; employee = await Employee.select().order_by( Employee.salary.desc() ).first(False) print(employee) # {&amp;#39;id&amp;#39;: 1, &amp;#39;name&amp;#39;: &amp;#39;at7h&amp;#39;, &amp;#39;department&amp;#39;: 1, &amp;#39;salary&amp;#39;: 15000.0} SQL 执行 SQL 有时你可能迫不得已想要执行一些原始的 SQL 语句，那么你可以使用 db.raw 函数来实现。 await db.raw(&amp;#34;SELECT * FROM `user` WHERE `id` &amp;lt; %s;&amp;#34;, params=[10]) 查看 SQL 为方便调试，有时候需要查看执行的 SQL，在 helo 中，你可以: 第一种方式，在初始化 db 时，设置 debug 为 True 即可，这样你将在日志输出中看到执行过的所有 SQL 语句。 db = helo.G(debug=True) 第二种方式主要是方便学习和调试，你可以使用 repr 函数(或在 REPR 环境中)和 str 函数来查看 Insert, Update, Select 等对象，我们拿上面的示例来举个例子： &amp;gt;&amp;gt;&amp;gt; q1 = Employee.update( ... salary=Employee.salary + 1000 ... ).where( ... (Employee.department.in_([1, 2])) | (Employee.name == &amp;#39;at7h&amp;#39;) ... ) &amp;gt;&amp;gt;&amp;gt; q1 Query(UPDATE `employee` SET `salary` = (`salary` + %s) WHERE ((`department` IN %s) OR (`name` = %s)); % ((1000.0,), (1, 2), &amp;#39;at7h&amp;#39;)) &amp;gt;&amp;gt;&amp;gt; q2 = User.select( ... User.name, helo.F.COUNT(helo.SQL(&amp;#39;1&amp;#39;)).as_(&amp;#39;posts&amp;#39;) ... ).join( ... Post, helo.JOINTYPE.LEFT, on=(User.id == Post.author) ... ).group_by( ... User.name ... ) &amp;gt;&amp;gt;&amp;gt; print(q2) SELECT `t1`.`name`, COUNT(1) AS `posts` FROM `user` AS `t1` LEFT JOIN `post` AS `t2` ON (`t1`.`id` = `t2`.`author`) GROUP BY `t1`.`name`; % () 本篇上手指南就到此结束。 十分欢迎大家的使用，有任何问题可随时与我交流或到 项目仓库 反馈，欢迎以任何形式提出任何问题或建议。 感谢 🤝</description>
    </item>
    
    <item>
      <title>Golang 零值、空值与空结构</title>
      <link>https://at7h.com/posts/go-null/</link>
      <pubDate>Sat, 01 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/go-null/</guid>
      <description>这篇文章我们讨论下有关 Golang 中的零值（The zero value）、空值（nil）和空结构（The empty struct）的相关问题以及它们的一些用途。 零值 零值是指当你声明变量（分配内存）并未显式初始化时，始终为你的变量自动设置一个默认初始值的策略。 首先我们来看看官方有关零值（The zero value）的规范： When storage is allocated for a variable, either through a declaration or a call of new, or when a new value is created, either through a composite literal or a call of make, and no explicit initialization is provided, the variable or value is given a default value. Each element of such a variable or value is set to the zero value for its type: false for booleans, 0 for numeric types, &amp;quot;&amp;rdquo; for strings, and nil for pointers, functions, interfaces, slices, channels, and maps. This initialization is done recursively, so for instance each element of an array of structs will have its fields zeroed if no value is specified. 据此我们可总结出： 对于值类型：布尔类型为 false, 数值类型为 0，字符串为 &amp;quot;&amp;quot;，数组和结构会递归初始化其元素或字段，即其初始值取决于元素或字段。 对于引用类型： 均为 nil，包括指针 pointer，函数 function，接口 interface，切片 slice，管道 channel，映射 map。 通常，为你声明的变量赋予一个默认值是有用的，尤其是为你数组和结构中的元素或字段设置默认值，这是一种保证安全性和正确性的做法，同时也可以让你的代码保持简洁。 比如，下面的示例是我们常用的，结构体 Value 中包含两个 unexported 字段，sync.Mutex 中也有两个 unexported 字段。因为有默认零值，所以我们可以直接使用： package main import &amp;#34;sync&amp;#34; type Value struct { mu sync.Mutex val int } func (v *Value)Incr(){ defer v.mu.Unlock() v.mu.Lock() v.val++ } func main() { var i Value i.Incr() } 因为切片是引用类型的，所以其零值也是 nil： package main import &amp;#34;fmt&amp;#34; import &amp;#34;strings&amp;#34; func main(){ var s []string fmt.Println(s, len(s), cap(s)) // [] 0 0 fmt.Println(s == nil) // true s = append(s, &amp;#34;Hello&amp;#34;) s = append(s, &amp;#34;World&amp;#34;) fmt.Println(strings.Join(s, &amp;#34;, &amp;#34;)) // Hello, World } 下面的情况需要特别注意下，有时候不注意就容易混淆，:= 语法糖是声明并且初始化变量的，所以是一个真正的实例（为其分配了内存地址的），并不是零值 nil： package main import &amp;#34;fmt&amp;#34; import &amp;#34;reflect&amp;#34; func main() { var s1 []string s2 := []string{} // 或者等同于 var s2 = []string{} fmt.Println(s1 == nil) // true fmt.Println(s2 == nil) // false fmt.Println(reflect.DeepEqual(s1, s2)) // false fmt.Println(reflect.DeepEqual(s1, []string{})) // false fmt.Println(reflect.DeepEqual(s2, []string{})) // true } 另外，对于空结构的 nil 是可以调用该类型的方法的，这还可以用来简单地提供默认值： package main import &amp;#34;fmt&amp;#34; const defaultPath = &amp;#34;/usr/bin/&amp;#34; type Config struct { path string } func (c *Config) Path() string { if c == nil { return defaultPath } return c.path } func main() { var c1 *Config var c2 = &amp;amp;Config{ path: &amp;#34;/usr/local/bin/&amp;#34;, } fmt.Println(c1.Path(), c2.Path()) } nil 对于一个刚开始使用 Golang 的开发人员，刚开始接触 nil 应该是使用它来检查错误，大致像这样： func doSomething() error { return nil } func main(){ if doSomething() != nil { return err } } 这是 Golang 惯用的，它鼓励开发人员显式的的将错误作为返回值来处理。现在我们来讨论下这个 nil，在其他语言中也有类似的定义，比如 C、C++、Java 等中的 null，Python 中的 None，但是 Goalng 中的 nil 与它们有着很多区别。 nil 是 Golang 中预先声明的标识符（非关键字保留字），其主要用来表示引用类型的零值（指针，接口，函数，映射，切片和通道），表示它们未初始化的值。 // [src/builtin/builtin.go](https://golang.org/src/builtin/builtin.go#L98) // // nil is a predeclared identifier representing the zero value for a // pointer, channel, func, interface, map, or slice type. var nil Type // Type must be a pointer, channel, func, interface, map, or slice type nil 是 Golang 中唯一没有默认类型的非类型化的值，它不是一个未定义的状态。所以你不能像这样使用它： a := nil // cannot declare variable as untyped nil: a 将一个并没有类型 nil 的值赋给 a 是不对的，编译器不知道它该给 a 分配什么类型。 值得一提的是 Golang 中比较出名的 nil != nil 的问题，我们来看下面的一个例子： var p *int var i interface{} fmt.Println(p) // &amp;lt;nil&amp;gt; fmt.Println(i) // &amp;lt;nil&amp;gt; fmt.Println(p == i) // false Why？为什么同样都是 nil 却不相等呢？ 带着问题，我们再来看一个下面的例子（来自官方 Why is my nil error value not equal to nil）: func Foo() error { var err *MyError = nil if bad() { err = ErrBad } return err } func main() { err := Foo() fmt.Println(err) // &amp;lt;nil&amp;gt; fmt.Println(err == nil) // false } 其罪魁祸首就是 interface，接口相关的实现原理不在本文的讨论范围，后面再具体分享。其大致原理是，接口要确定一个变量需要两个基础属性：Type and Value，下面我们给上面的两段代码加上注释，就明白了： var p *int // (T=*int,V=nil) var i interface{} // (T=nil,V=nil) fmt.Println(p == i) // (T=*int, V=nil) == (T=nil, V=nil) -&amp;gt; false func Foo() error { var err *PathError = nil // (T=*PathError, V=nil) if bad() { err = ErrBad } return err // 这将始终返回 non-nil 错误 } func main() { err := Foo() fmt.Println(err) // &amp;lt;nil&amp;gt; fmt.Println(err == nil) // (T=*PathError, V=nil) == (T=nil, V=nil) -&amp;gt; false } 请注意：为了避免此问题，返回错误时请永远使用 error 接口，并且永远不要初始化可能从函数返回的空错误变量。 我们将上面的例子再改改，看下面的例子： var p *int // (T=*int, V=nil) var i interface{} // (T=nil, V=nil) fmt.Println(p == nil) // true fmt.Println(i == nil) // true i = p fmt.Println(i == nil) // (T=*int, V=nil) == (T=nil, V=nil) -&amp;gt; false 这个问题的实质就是 Go Tour 中的 Interface values with nil underlying values。 示例中 i 可以传递给一个 interface{} 作为输入参数的函数，你只检查 i == nil 是不够的。所以对于接口类型的空指针的判断，有些时候你并不能安全的依靠 v == nil，尽管这种检查的坑很少发生，但这有时候可能会使你的程序崩溃。对此，可以有两种方式解决，你可以分别将类型和值分别和 nil 比较或者使用反射包 reflect。 请记住：如果接口中已存储任何具体值，那么接口将不会是 nil，详见反射定律。 还有就是，也许你也感到困惑，还是上面的例子，为什么下面的类型就可以直接比较并获得准确的结果： var p *int // (T=*int, V=nil) fmt.Println(p == nil) // true 这是因为在进行上面的比较时，因为编译器已经清楚的知道了 p 的类型，所以编译器可以转化为 p == (*int)(nil)。但是对于接口，编译器是没法确定底层类型的，因为它是可以被更改的。 空结构 空结构是没有任何字段的结构类型，例如： type Q struct{} var q struct{} 既然没有任何字段，那它有什么用呢？ 我们知道，一个结构的实例的大小(即所占存储空间的字节数)是由其字段的宽度（size）和对齐（alignment）共同决定的，这样有助于寻址速度，C 语言等都有类似的策略，关于 Golang 的具体策略请阅读 Size and alignment guarantees。 很显然，空结构的占用空间大小为零字节: var q struct {} fmt.Println(unsafe.Sizeof(q)) // 0 由于空结构占用零字节，因此不需要填充对齐，所以由嵌套空结构的空结构也不会占用存储空间。 type Q struct { A struct{} B struct{ C struct{} } } var q Q fmt.Println(unsafe.Sizeof(q)) // 0 由于空结构不占用内存空间，所以我们声明以空结构作为元素的数组或切片，也是不占用空间的（Orthogonality in Go）： var x [1000000000]struct{} fmt.Println(unsafe.Sizeof(x)) // 0 var y = make([]struct{}，1000000000) fmt.Println(unsafe.Sizeof(x))// 24，背后关联数组为 0 对于空结构（或者空数组），其占用的存储大小为零，所以两个不同的零大小的变量在内存中可能具有相同的地址。 来看下面几个示例： var a, b struct{} fmt.Println(&amp;amp;a == &amp;amp;b) // true c := make([]struct{}, 10) d := make([]struct{}, 20) fmt.Println(&amp;amp;c[0] == &amp;amp;d[1]) // true type Q struct{} func (q *Q)addr() { fmt.Printf(&amp;#34;%p\n&amp;#34;, q) } func main() { var a, b Q a.addr() // 0x5af5a60 b.addr() // 0x5af5a60 } e := struct{}{} // 不是零值，一个真正的实例 f := struct{}{} fmt.Println(e == f) // true 请注意，这种相等只是可能，并不是一定的。 比如这个示例，相关问题解释请看这个 issue。 说了半天，你可能会想，貌似这些也没什么实际的用途啊，下面列举两个比较实用的实践用途： 1. 使用 chan struct{} 代替 chan bool 在 goroutines 之间传递信号。使用 bool 容易让人不理解该值，true or false，但是使用 chan struct{} 就很清楚，我们不在乎值，只关心发生的事儿，更容易表达清楚一些。 2. 为了防止 unkeyed 初始化结构，可以添加 _ struct {} 字段： type Q struct { X, Y int _ struct{} 这样一来，使用 Q{X: 1, Y: 1} 可以，但使用 Q{1, 1} 就会出现编译错误：too few values in struct initializer，同时这样也帮助了 go ver 代码检查。 参考 The Go Programming Language Specification Golang Frequently Asked Questions Why Golang Nil Is Not Always Nil? Nil Explained</description>
    </item>
    
    <item>
      <title>武器修炼之 Neo/vim 与 Tmux</title>
      <link>https://at7h.com/posts/my-dotfiles/</link>
      <pubDate>Sun, 26 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/my-dotfiles/</guid>
      <description>古人云：工欲善其事，必先利其器。 一直以来，我都觉得应该好好修炼一个自己趁手的『武器』，这篇文章跟大家谈一谈我的一点点修炼感受。 你可以选择修炼 vim、emacs 等编辑器，如果你不喜欢折腾也可以直接使用 IDE。这个话题貌似比较敏感，很多人都在讨论，我个人感觉完全是个人审美或是爱好而已，说到底『武器』只是辅助工具，只要用的顺手，能很好够满足自己的功能、审美等需求即可，最重要的还是自己本身的『武功』，如果你『武功』足够高，不需要借助工具帮助提高效率，不要补全不要 lint 这那的，用『记事本』也不耽误你写出牛逼的代码。 我的选择是做个 vimer。修炼路且长，下面来谈一下我自己的一点入坑感受和建议，希望可以帮助那些还在迷茫的想要入门的童鞋。老鸟就跳过吧，感兴趣的话可以关注下我的配置，提提建议、意见，交流交流，共同进步。 入坑建议 作为一个爱『折腾』的人，学生时代也用过一些主流的 IDE，最后弃用的原因就是觉得太重了，太多的功能用不上，更不想那么多这那的窗口挡住我的代码 😂。在用了一段时间 sublime 之后，最终决定开始入坑 vim，后来因为异步、floating window 等切到了 neovim，当然这些现在 vim 也都支持了，再后来接触到 tmux，就圆满了 😎。 Tmux 是一款优秀的终端复用软件，由于很长一段时间我的开发都是登录远程主机上进行的，这时候 tmux 神器简直就让你爽到起飞。本地开发的话，多个项目终端之间切换，也是非常有用。跟 vim 类似，刚开始也是有一定的上手使用和配置难度，中间放弃了一次，但是入坑之后，就就就就，爽的飞起~ 作为一个流行了三十多年的非常优秀的编辑器，我是非常喜欢它的设计哲学的，说的直白一点就是它的工作模式吧。还有一个很重要的方面就是，每一次你在折腾配置折腾插件的时候，它总是时不时的能给你带来惊喜，也许很小的一点改动却可以大幅提高你使用的『幸福度』。 很多人觉得它的上手难度比较大，学习曲线有些陡峭，看别人用的很溜，自己上手就不知所措，那么多快捷键、命令怎么记得住，配置好难搞哦等等，慢慢就弃坑了。 个人觉得是这样，刚开始的时候你得想清楚你学它的目的，是真正的喜欢想修炼自己的『武器』？还是就是看人家用好溜，也想学上一手装个 B 呢？一直在说，工具只是工具，辅助你高效率的写代码而已，如果你自身『武功』足够高，用『记事本』也不耽误你写出牛逼的代码，要毛补全要毛 Lint。就是说，首先你得搞清楚了是为了什么，IDE 好好的为啥非要辛苦折腾这样那样配置呢，得明白你是为了满足什么需求解决什么问题。 Sorry，貌似跑题了。回到正题，刚开始没办法，就是硬着头皮上，上手用，刚开始你可能，哦不对，是肯定是觉得真难用，是的，没有任何配置的情况下确实不怎么好用，所以你就要想办法让它『好用起来』。对于配置，我是建议自己慢慢来『攒』你的自己配置，一行一行自己来搞，这个配置是干嘛的这个插件是干嘛的，搞清楚，一点一点来，积累形成一套适合自己的风格。可以并且鼓励去参考一些别人的优秀的配置、解决方案，但是要弄懂，不要一把梭照搬过来。 当然现在有很多很成熟的产品级的解决方案比如 spaceVim，你可以直接拿来根据教程快速的上手用起来，但刚开始它对你就像是个黑盒子，哪里出了问题，或者你想修改点东西都可能无从下手。 Vim 里面的东西还是比较复杂的，个人觉得你是日常使用的话，肯定是比较注重实际的使用，没必要一开始就像学习一门课程一样系统的学，今天学完明天也许就忘了，更没必要去记那些这样那样的命令、快捷键。就直接上手干就完了（当然也不是说一点也不看教程，最开始肯定还是要先看一些简单的入门帖子，必备技能还是要学一下子的，不然刚开始就没法玩儿），遇到不会搞的就查，查文档，问搜索引擎，用的多了自然就会了，按的多了自然就记住了，长期的肌肉记忆根本就不需要过脑子想这个怎么按，时间长了，你遇到的问题、需求多了，自然就入门了。对插件也是一样，不要一开始就去完全照搬别人的配置，一大堆插件一把梭都装上，也不知道一个个是干嘛的，最好还是根据自己的需要一个一个来，好好看下每个插件仓库的文档，看下怎么使用。 Tmux 也是一样，可以额先看下基础的一些帖子或者官方文档，然后主要是上手用，就干就完了。配置也一样，也是建议自己搞，不要一开始全部照搬，每个人习惯不一样，别人喜欢的未必就是你喜欢的，『拿来』可以，但是前提是你要能吸收理解，能驾驭。 1. Neo/vim 下查看文档可以输入 : 进入 COMMAND 模式 help，这里的文档也就是它的官方文档，这里是翻译中文文档。 2. Tmux 可以看官方仓库的 Getting-Started，像我这种英文不怎么能看明白的还是要再去搜一些相关的介绍文章看看。 不要放弃，硬着头发干，等真正用起来之后，相信我，你肯定会爱上它们的 😏 😏 ~ 我的分享 最后，分享下我的配置： https://github.com/at7h/dots 对你有用的话，请帮忙点个 Star，感谢 😊 当然，也十分欢迎大家来交流自己的想法、心得、配置 …… 大家有问题欢迎评论留言，我会第一时间回复。</description>
    </item>
    
    <item>
      <title>理解 Python 类属性 __slots__</title>
      <link>https://at7h.com/posts/py-slots/</link>
      <pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/py-slots/</guid>
      <description>网络上有一篇比较有名的文章叫 Saving 9 GB of RAM with Python’s __slots__，文章示例中仅对 Image 类添加了一个 __slots__属性就为服务器节省了 9G 的内存占用。如果有同学看过一些开源的 Python ORM，如 SQLAlchemy, peewee 等，或是看过一些进行 IO 处理的包，你就会在其中发现很多 __slots__ 的身影。 那么，这个 __slots__ 到底是什么？ 下面的解释整理自 Python 官方文档： object.__slots__ 是一个类变量，可赋值为字符串、可迭代对象或由实例使用的变量名构成的字符串序列。其允许我们显式地声明数据成员（如特征属性），为已声明的变量保留空间，并禁止为每个实例创建 __dict__ 和 __weakref__。 举个例子： class X: def __init__(self, a, b): self.a = a self.b = b class Y: __slots__ = (&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;) def __init__(self, a, b): &amp;#34;&amp;#34;&amp;#34; 此时如果你声明一个 __slots__ 中没有的属性，如 self.c = 1 pylint 等就会提示错误： [pylint] [Error] Assigning to attribute &amp;#39;c&amp;#39; not defined in class slots 当然如果你执意要写的话，初始化实例的时候会引发 AttributeError： AttributeError: &amp;#39;Y&amp;#39; object has no attribute &amp;#39;c&amp;#39; &amp;#34;&amp;#34;&amp;#34; self.a = a self.b = b &amp;gt;&amp;gt;&amp;gt; import weakref &amp;gt;&amp;gt;&amp;gt; x = X(7, 8) &amp;gt;&amp;gt;&amp;gt; x.a 7 &amp;gt;&amp;gt;&amp;gt; x.c = 9 &amp;gt;&amp;gt;&amp;gt; x.__dict__ {&amp;#39;a&amp;#39;: 7, &amp;#39;b&amp;#39;: 8, &amp;#39;c&amp;#39;: 9} &amp;gt;&amp;gt;&amp;gt; rx = weakref.ref(x) &amp;gt;&amp;gt;&amp;gt; rx &amp;lt;weakref at 0x107a9e278; to &amp;#39;X&amp;#39; at 0x107618f98&amp;gt; &amp;gt;&amp;gt;&amp;gt; y = Y(7, 8) &amp;gt;&amp;gt;&amp;gt; y.a 7 &amp;gt;&amp;gt;&amp;gt; y.c = 9 AttributeError: &amp;#39;Y&amp;#39; object has no attribute &amp;#39;c&amp;#39; &amp;gt;&amp;gt;&amp;gt; y.__dict__ AttributeError: &amp;#39;Y&amp;#39; object has no attribute &amp;#39;__dict__&amp;#39; &amp;gt;&amp;gt;&amp;gt; ry = weakref.ref(y) TypeError: cannot create weak reference to &amp;#39;Y&amp;#39; object 那使用 __slots__ 到底有什么作用呢？🤔 答案是与 __dict__ 相比，使用 __slots__ 的方式可以显著地节省内存空间，提升属性的查找速度。 之所以会在 ORM 等项目里频繁使用，正是因为这些项目中存在特别多大量创建实例的操作，使用 __slots__ 会明显减少内存的使用，提升速度。并且随着实例数目的增加，其效果会更加显著。 几点疑问 至此，你可能会有几点疑问： 为什么 __slots__ 可以节省内存，提高速度的？ 咋通过 __slots__ 来实现属性的存储与访问的？ 使用了 __slots__ 的类怎么实现动态赋值，如果需要实例弱引用支持怎么搞？ 使用了 __slots__ 的类继承与被继承时的表现？ 针对这几个问题作答： 1. 通常情况下，类实例使用 __dict__来存储其属性数据，好处是允许我们在运行时动态的设置实例属性，然而 dict 哈希表本身的数据结构决定了它需要更多的内存，当创建的实例越多，或者实例的属性越多时，内存的耗费将更加严重。__slots__ 保证了解释器在编译时期就知道这个类具有什么属性，以分配固定的空间来存储已知的属性。 2. 使用 __slots__ 时，会将属性的存储从实例的 __dict__ 改为类的 __dict__ 中： &amp;gt;&amp;gt;&amp;gt; Y.__dict__ mappingproxy({&amp;#39;__module__&amp;#39;: &amp;#39;__main__&amp;#39;, &amp;#39;__slots__&amp;#39;: (&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;), &amp;#39;__init__&amp;#39;: &amp;lt;function __main__.Y.__init__(self, a, b)&amp;gt;, &amp;#39;a&amp;#39;: &amp;lt;member &amp;#39;a&amp;#39; of &amp;#39;Y&amp;#39; objects&amp;gt;, &amp;#39;b&amp;#39;: &amp;lt;member &amp;#39;b&amp;#39; of &amp;#39;Y&amp;#39; objects&amp;gt;, &amp;#39;__doc__&amp;#39;: None}) 属性的访问是通过在类层级上为每个 slot 变量创建和 实现描述器(descriptor) 实现的，该描述器知道属性值在实例列表中的唯一位置。关于描述器与属性的访问在我的 走进 Python 类的内部 一文中均有详细的解释，感兴趣的同学可前去阅读。另外，这篇 how __slots__ are implemented 也许可以帮助你的理解，尽管我看它写于很多年前，但至今依然有借鉴意义。 3.. 怎么实现动态赋值和弱引用支持？答案是：在 __slots__ 中加上 __dict__ 和 __weakref__。 class Y: __slots__ = (&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;__dict__&amp;#39;, &amp;#39;__weakref__&amp;#39;) def __init__(self, a, b): self.a = a self.b = b &amp;gt;&amp;gt;&amp;gt; import weakref &amp;gt;&amp;gt;&amp;gt; y = Y(7, 8) &amp;gt;&amp;gt;&amp;gt; y.a 7 &amp;gt;&amp;gt;&amp;gt; y.b 8 &amp;gt;&amp;gt;&amp;gt; y.c = 9 &amp;gt;&amp;gt;&amp;gt; y.__dict__ {&amp;#39;c&amp;#39;: 9} &amp;gt;&amp;gt;&amp;gt; ry = weakref.ref(y) &amp;gt;&amp;gt;&amp;gt; ry &amp;lt;weakref at 0x107d17d68; to &amp;#39;Y&amp;#39; at 0x107a4d480&amp;gt; 4. 当类继承自一个未定义 __slots__ 的类时，实例的 __dict__ 和 __weakref__ 属性将总是可访问的。 class X: def __init__(self): self.a = 7 class Y(X): __slots__ = (&amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;) def __init__(self): super().__init__() self.b = 8 self.c = 9 &amp;gt;&amp;gt;&amp;gt; y = Y() &amp;gt;&amp;gt;&amp;gt; y.a 7 &amp;gt;&amp;gt;&amp;gt; y.b 8 &amp;gt;&amp;gt;&amp;gt; y.__dict__ {&amp;#39;a&amp;#39;: 7} 5. 在父类中声明的 __slots__ 在其子类中同样可用。不过，子类将会获得 __dict__ 和 __weakref__，除非它们也定义了 __slots__ 。 class X: __slots__=(&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;) def __init__(self): self.a = 7 self.b = 8 class Y(X): &amp;#34;&amp;#34;&amp;#34;没有定义 __slots__&amp;#34;&amp;#34;&amp;#34; class Z(X): __slots__ = () &amp;gt;&amp;gt;&amp;gt; y = Y() &amp;gt;&amp;gt;&amp;gt; y.a 7 &amp;gt;&amp;gt;&amp;gt; y.b 8 &amp;gt;&amp;gt;&amp;gt; y.c = 9 &amp;gt;&amp;gt;&amp;gt; y.__dict__ {&amp;#39;c&amp;#39;: 9} &amp;gt;&amp;gt;&amp;gt; z = Z() &amp;gt;&amp;gt;&amp;gt; z.a 7 &amp;gt;&amp;gt;&amp;gt; z.b 8 &amp;gt;&amp;gt;&amp;gt; z.c = 9 AttributeError: &amp;#39;Z&amp;#39; object has no attribute &amp;#39;c&amp;#39; 所以，由 4，5 可知如果需要使用 __slots__, 那么从基类到每个继承的子类都要定义 __slots__。 注意事项 非空的 __slots__ 不适用于派生自「可变长度」内置类型（如 int、str 和 tuple 的派生类）。 __class__ 赋值仅在两个类具有相同的 __slots__ 时才会起作用。 结论 尽管 __slots__ 可以节省内存空间，提高属性的访问速度，但也存在局限性和副作用，并不是用了就是好的，那么到底达到多大的实例规模的类推荐使用呢？这个我也没有具体做过实验，感兴趣的同学可以自行搜索相关论文。在不同的业务场景下，衡量方式也会不同，绝不会是说用 __slots__ 就是好的，必须是需要根据具体场景来决定。</description>
    </item>
    
    <item>
      <title>Python 可迭代对象, 迭代器与生成器</title>
      <link>https://at7h.com/posts/iter/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/iter/</guid>
      <description>这篇文章主要讨论下 Python 中的容器迭代协议，它的实现统一约定了容器对象的迭代方案，允许我们自定义类对迭代的支持。在 Python 中有很多的协议，比如迭代器协议，描述器协议等等，这些协议比较类似于其他面向对象语言中接口的概念。 本文主要介绍内容为可迭代对象、迭代器和生成器。 可迭代对象(iterable) 以通俗简单的方式来讲，可迭代对象就是能够逐一返回其成员项的对象，其可用于 for 循环以及许多其他需要一个序列的地方 zip、map 等等。例如： 序列(sequence)类型： 如 list, str, tuple, bytes 等 非序列类型类型如：dict, 文件对象等 严格来说，可迭代对象是任何实现了 __iter__() 方法或者实现了序列(Sequence)语义中的 __getitem__() 方法的任意自定义类对象。 那么下面我们分别来讨论下这两种实现方案。 1. 实现 __iter__ 这种方式是你必须为你的类实现 __iter__()方法，该方法返回的必须是一个迭代器对象，下面会讲到。 2. 实现 __getitem__ 序列(Sequence)的迭代通过实现 __getitem__() 方法来使用整数索引进行高效的元素访问。同时，你必须为其定义一个返回序列长度的 __len__() 方法。例如上面例子中的 list, str, tuple, bytes。序列数据结构的存储是一段连续的内存空间，其直接使用整数索引进行寻址，查找元素非常高效，但是插入删除元素时效率低下。 有的童鞋会说，dict 也实现了 __getitem__ 和 __len__ 协议，为毛 dict 不属于序列？原因是它并不是通过整数索引来顺序迭代，而是通过任意的不可变键(immutable key) 来进行逐个查找的。所以 dict 的迭代还是因为其实现了 __iter__。 工作方式 当把一个可迭代对象 x 作为参数传给内置函数 iter() 时，它会返回该对象的迭代器以供迭代。但通常我们并不需要这么搞，当我们使用 for 对可迭代对象进行遍历时，for 语句会为你自动处理那些操作，即自动调用 iter(x) 来获取迭代器，若对象没有实现__iter__()方法，而实现了方式二的 __getitem__ 和 __len__ 协议，其会自动创建一个迭代器，并尝试从索引 0 开始获取元素，若尝试失败，会引发一个 TypeError。 类型断言 判断一个对象是否是一个可迭代对象，可以使用 collections.abc.Iterable。 In [1]: from collections.abc import Iterable In [2]: isinstance([1, 2, 3], Iterable) Out[2]: True In [3]: isinstance(1, Iterable) Out[3]: False In [4]: isinstance(&amp;#39;1&amp;#39;, Iterable) Out[4]: True In [5]: isinstance({}, Iterable) Out[5]: True 迭代器(iterator) 上面多次提到了迭代器，那么什么是迭代器？即实现了迭代器协议的对象就是一个迭代器，迭代器协议由 __iter__() 和 __next__() 共同组成。以 Golang 接口的思维理解就是任何实现了这俩方法的对象就是迭代器。 是的，又有 __iter__()，所以迭代器必定也是可迭代对象。在迭代器中: __iter__() 必须返回迭代器对象本身。 __next__() 应从容器中返回下一项，如果已经没有数据项可返回时，则需引发 StopIteration 异常，继续调用其 __next__() 应再次引发 StopIteration 异常。 所以一个迭代器应有的样子应该是这样的： class Iterator: def __iter__(self): return self def __next__(self): pass 工作方式 迭代器用来表示一连串数据流的对象，当 for 语句自动返回可迭代对象的迭代器时，for 将重复调用其 __next__() 方法将逐个返回流中的项，直到迭代器引发 StopIteration 异常后终止循环。此时该迭代器数据项已耗尽，不能再使用。我们可以通过将迭代器传给 next() 函数来模拟: In [11]: iterator = iter([1, 2, 3]) # 手动创建一个迭代器 In [12]: for i in iterator: ...: print(i) ...: 1 2 3 In [13]: next(iterator) # 该迭代器已耗尽 --------------------------------------------------------------------------- StopIteration Traceback (most recent call last) &amp;lt;ipython-input-13-4ce711c44abc&amp;gt; in &amp;lt;module&amp;gt; ----&amp;gt; 1 next(iterator) StopIteration: In [14]: iterator = iter([1, 2, 3]) In [15]: next(iterator) Out[15]: 1 In [16]: next(iterator) Out[16]: 2 In [17]: next(iterator) Out[17]: 3 In [18]: next(iterator) --------------------------------------------------------------------------- StopIteration Traceback (most recent call last) &amp;lt;ipython-input-18-4ce711c44abc&amp;gt; in &amp;lt;module&amp;gt; ----&amp;gt; 1 next(iterator) StopIteration: 类型 判断一个对象是否是一个迭代器，可以使用 collections.abc.Iterator。 In [31]: from collections.abc import Iterator In [32]: iterator = iter([1, 2, 3]) In [33]: isinstance(iterator, Iterator) Out[33]: True In [34]: isinstance([],Iterator) Out[34]: False 练习 通过上面的介绍，你可能或多或少的了解了什么是可迭代对象 iterable，什么是迭代器 iterator。一句话简单的总结就是，当我们对可迭代对象进行迭代时，就从可迭代对象获取迭代器进行迭代。 下面我们来写一个非常简单的一段文本处理的示例，从下面一段 HTML 文本中提取出所有 a 标签的 href。 TEXT = (&amp;#39;&amp;lt;div&amp;gt;&amp;lt;a href=&amp;#34;https://blog.python.org&amp;#34; title=&amp;#34;More News&amp;#34;&amp;gt;More&amp;lt;/a&amp;gt;&amp;lt;ul class=&amp;#34;menu&amp;#34;&amp;gt;&amp;#39; &amp;#39;&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;http://feedproxy.google.com/~r/PythonSoftwareFoundationNew/~3/T3r7qZxo-xg&amp;#39; &amp;#39;/python-software-foundation-fellow.html&amp;#34;&amp;gt;Python Software Foundation Fellow Members for&amp;#39; &amp;#39;Q3 2019&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt; &amp;lt;a href=&amp;#34;http://feedproxy.google.com/~r/PythonSoftwareFoundationNews&amp;#39; &amp;#39;/~3/lE0u-5MIUQc/why-sponsor-pycon-2020.html&amp;#34;&amp;gt;Why Sponsor PyCon 2020?&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#39; &amp;#39;&amp;#34;http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/jAMRqiPhWSs/seeking-developers&amp;#39; &amp;#39;-for-paid-contract.html&amp;#34;&amp;gt;Developers for Paid Contract Improving pip&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;/div&amp;gt;&amp;#39;) class LinkFinder: PATTERN = &amp;#34;(?&amp;lt;=href=\&amp;#34;).+?(?=\&amp;#34;)|(?&amp;lt;=href=\&amp;#39;).+?(?=\&amp;#39;)&amp;#34; def __init__(self, text): self.links = re.findall(self.PATTERN, text) def __iter__(self): return LinkIiterator(self.links) class LinkIiterator: def __init__(self, links): self.links = links self.index = 0 def __iter__(self): return self def __next__(self): try: link = self.links[self.index] except IndexError: raise StopIteration self.index += 1 return link 稍稍验证一下: In [39]: for link in LinkFinder(TEXT): ...: print(link) ...: https://blog.python.org http://feedproxy.google.com/~r/PythonSoftwareFoundationNew/~3/T3r7qZxo-xg/python-software-foundation-fellow.html http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/lE0u-5MIUQc/why-sponsor-pycon-2020.html http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/jAMRqiPhWSs/seeking-developers-for-paid-contract.html 生成器(generator) 看完上面的例子，有同学可能会想，能不能省掉 LinkIiterator 呢？有没有一种机制能够让 __iter__() 返回的对象自动提供 __iter__() 和 __next__() 方法呢？ 有，那就是生成器（generator）。 一个包含 yield 的函数就是一个生成器函数(通常称其为生成器)，当其被调用的时，会返回一个迭代器，称为生成器迭代器(generator iterator)。yield 表达式会产生一系列值来供给 for 循环使用或是通过 next() 函数逐一获取。每个 yield 会临时暂停处理，记住当前位置执行状态(包括局部变量，指令指针，内部求值栈和任何异常处理的状态等)，当该生成器迭代器恢复时，它会从离开位置继续执行，这与每次调用都从新开始的普通函数差别很大。因本文主要讲迭代协议，所以关于生成器的实现部分暂不具体讨论。 生成器机制提供了一种实现迭代器协议的便捷方式。 即如果我们把容器对象 __iter__() 方法实现为一个生成器，那么它将返回一个生成器迭代器对象(generator iterator)，该对象提供 __iter__() 和 __next__() 方法以供迭代。 我们将上面的例子改成生成器版： class LinkFinder: PATTERN = &amp;#34;(?&amp;lt;=href=\&amp;#34;).+?(?=\&amp;#34;)|(?&amp;lt;=href=\&amp;#39;).+?(?=\&amp;#39;)&amp;#34; def __init__(self, text): self.links = re.findall(self.PATTERN, text) def __iter__(self): for link in self.links: yield link 验证下： In [40]: for link in LinkFinder(TEXT): ...: print(link) ...: https://blog.python.org http://feedproxy.google.com/~r/PythonSoftwareFoundationNew/~3/T3r7qZxo-xg/python-software-foundation-fellow.html http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/lE0u-5MIUQc/why-sponsor-pycon-2020.html http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/jAMRqiPhWSs/seeking-developers-for-paid-contract.html 优化 本小节其实属于多余部分，关于迭代协议的讨论基本已经结束，但通过上面关于生成器的介绍我们发现，生成器迭代器与普通迭代器的一个显著区别就是，其往往是随用随生成，而不是一次性生成完毕，这在迭代大量数据时将非常有用，不用一次性计算或载入全部的数据到内存。所以上面的例子还有待优化。因为 links 列表是一次性计算好的。可以使用 re.finditer 方法，对 links 进行惰性求值： class LinkFinder: PATTERN = &amp;#34;(?&amp;lt;=href=\&amp;#34;).+?(?=\&amp;#34;)|(?&amp;lt;=href=\&amp;#39;).+?(?=\&amp;#39;)&amp;#34; def __init__(self, text): self.links = re.finditer(self.PATTERN, text) def __iter__(self): for link in self.links: yield link.group() 还可以使用一种更加简洁的方式，即使用生成器表达式： def __iter__(self): return (link.group() for link in self.links)</description>
    </item>
    
    <item>
      <title>闲侃 sys.path 与 buildout 实践</title>
      <link>https://at7h.com/posts/py-syspath/</link>
      <pubDate>Mon, 15 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/py-syspath/</guid>
      <description>这篇文章我们来讨论下 Python 中的 sys.path，以及其在 buildout 中的应用与实践，最后分享下在 neo/vim 中给 python-mode 和 coc-python 添加自定义本地 Python 包路径的方法。 sys.path Python 中的 sys.path 是一个字符串列表，用于指定 Python Runtime 的模块搜索路径。 &amp;gt;&amp;gt;&amp;gt; import sys &amp;gt;&amp;gt;&amp;gt; sys.path [ &amp;#39;&amp;#39;, &amp;#39;/usr/local/lib/python27.zip&amp;#39;, &amp;#39;/usr/local/lib/python2.7&amp;#39;, &amp;#39;/usr/local/lib/python2.7/plat-darwin&amp;#39;, &amp;#39;/usr/local/lib/python2.7/plat-mac&amp;#39;, &amp;#39;/usr/local/lib/python2.7/plat-mac/lib-scriptpackages&amp;#39;, &amp;#39;/usr/local/lib/python2.7/lib-tk&amp;#39;, &amp;#39;/usr/local/lib/python2.7/lib-old&amp;#39;, &amp;#39;/usr/local/lib/python2.7/lib-dynload&amp;#39;, &amp;#39;/Users/jiawei/.local/lib/python2.7/site-packages&amp;#39;, &amp;#39;/usr/local/lib/python2.7/site-packages&amp;#39;, &amp;#39;/usr/local/lib/python2.7/site-packages/install-1.3.3-py2.7.egg&amp;#39; ] 该列表由以下三个部分组成，在程序启动时，会从以下三个方面进行初始化: 1. 第一部分 sys.path[0] 是你当前调用 python 解释器的脚本的目录，也就是你当前的 Python 项目路径，如果是在 REPL 环境中，其为空字符串 &amp;quot;&amp;quot;。 2. 第二部分是开发者可以修改控制的，通过几种方式读取开发者定义的模块路径，例如通过读取环境变量 PYTHONPATH 等，下面具体介绍。 3. 最后一部分是你 Python 安装相关的默认环境。 当我们在程序中导入 import m 时，可能会遇到 ImportError: No module named m 这种类似的包无法导入的问题时，原因在于它所在的路径不在 sys.path 里，下面我将列举向 sys.path 添加自定义模块路径几种方法。 1. 通过创建 .pth 文件，将目录列出来，例如： /my/prodir1 /my/prodir2 但这种方式我们通常是不提倡的，关于更多如何使用 .pth 文件拓展 sys.path 的介绍可以阅读 site 模块的描述。 2. 通过设置环境变量 PYTHONPATH，写过 Go 的朋友应该都比较熟悉，类似于 Golang 中有 GOROOT 和 GOPATH。 export PYTHONPATH=/my/prodir1:/my/prodir2 现在再来看看我们的 sys.path &amp;gt;&amp;gt;&amp;gt; import sys &amp;gt;&amp;gt;&amp;gt; sys.path [ &amp;#39;&amp;#39;, &amp;#39;/my/prodir1&amp;#39;, &amp;#39;/my/prodir2&amp;#39;, &amp;#39;/usr/local/lib/python27.zip&amp;#39;, &amp;#39;/usr/local/lib/python2.7&amp;#39;, &amp;#39;/usr/local/lib/python2.7/plat-darwin&amp;#39;, &amp;#39;/usr/local/lib/python2.7/plat-mac&amp;#39;, &amp;#39;/usr/local/lib/python2.7/plat-mac/lib-scriptpackages&amp;#39;, &amp;#39;/usr/local/lib/python2.7/lib-tk&amp;#39;, &amp;#39;/usr/local/lib/python2.7/lib-old&amp;#39;, &amp;#39;/usr/local/lib/python2.7/lib-dynload&amp;#39;, &amp;#39;/Users/jiawei/.local/lib/python2.7/site-packages&amp;#39;, &amp;#39;/usr/local/lib/python2.7/site-packages&amp;#39;, &amp;#39;/usr/local/lib/python2.7/site-packages/install-1.3.3-py2.7.egg&amp;#39; ] 3. 还有一种方式是写脚本来手动添加，在进入你程序的 work runtime 之前将路径插入到 sys.path中， 这种方式可以做到项目级，比较灵活： import sys sys.path.insert(0, &amp;#39;/my/prodir1&amp;#39;) sys.path.insert(0, &amp;#39;/my/prodir2&amp;#39;) 当然，上面只是一个简单的示例，实践中需要尽量避免硬编码，导致添加错误的路径。 buildout 对于一个 Python 开发者来说，虚拟环境工具你一定不陌生，例如 virtualenv，virtualenvwrapper，pipenv 等，它们通常提供了一个相对隔离的环境来存放和管理你需要的第三方包，并为你设置好 sys.path。不对，貌似有点跑题了，关于虚拟环境的工作原理我将在后面单独分享，下面请出本节的主角大哥大 buildout。 Buildout 是一个 Python 项目的自动化构建打包工具，通过它我们可以为大型系统创建复杂但可重用的设置。其主要根据配置将项目的依赖以 egg 包的形式全部归在统一的一个 eggs 目录下，这样就不用依赖任何外部的资源，比虚拟环境来得更彻底。egg 包 类似于 Java 中的 jar 包，想了解更多介绍的同学可以阅读这篇文章。 关于 buildout 的更多介绍和以及如何配置，官方文档上都有详细的介绍，而且因为本文的主题是 sys.path，所以这里就不赘述了。 这里我们主要关心它包的组织，eggs 会生成到你项目下的 buildout.cfg 配置中的 eggs-directory 目录下，而一般我们并不需要额外去配置，默认会生成在当前项目的根目录下，为你的项目使用。 当然 buildout 也支持在多个项目之间共享 eggs。这需要你新建 $HOME/.buildout/default.cfg 文件，设置用户级的默认配置： [buildout] eggs-directory = ~/.buildout/eggs download-cache = ~/.buildout/downloads 除此之外，你还可以通过每个 parts 下的 extra-paths 配置你本地的包： [buildout] parts = app [app] recipe = zc.recipe.egg interpreter = python eggs = my-pro-name extra-paths = ${buildout:directory}/my-extra-pkg 好，回到主题，既然是将依赖包打在项目里，所以要正确启动服务，buildout 肯定要将项目的所有依赖包 eggs 中的包路径以及 extra-paths 加入到 sys.path 中，它采用的方式是我们上面说的第三种，我们可以打开 bin 下生成的可执行文件一看便知： #!/Path/to/your/local/python import os, sys base = os.path.dirname(os.path.abspath(os.path.realpath(__file__))) base = os.path.dirname(base) sys.path[0:0] = [ base, &amp;#39;/path/to/local/pro/eggs/pkg1.egg&amp;#39;, &amp;#39;/path/to/local/pro/eggs/pkg2.egg&amp;#39;, # ... &amp;#39;/path/to/local/pro/my-extra-pkg&amp;#39; ] # ... 如果打包过程中，有一些包是你已经安装了，也就是在上面谈到的 sys.path 的第三部分的中的某个路径下，比如 /usr/local/lib/python2.7/site-packages, 那么在打包过程中就不会生成相应的 egg 包了，所以会在上述 sys.path 也会加上这个路径，因为 buildout 必须保证项目依赖包的完备性。 vim 插件支持 buildout 虽然很完美，但这也给 neo/vim 下的 Python 环境搭建带来了一点麻烦，据我所知目前的一些 Python 相关的插件并没有直接支持 buildout 的（PyCharm 是支持的，直接配置即可），所以并不能正确识别 buildout 的配置来加载我们项目的那些依赖包，在 rope init 或者 lint 时会报错找不到包，因此代码跳转补全等基础功能都会受到影响。所以我们必须要自己来处理这个问题，将上述依赖包加入到其运行时环境中。 当然你可以直接通过我们上述的几种方法来实现，但这不是我推荐的，因为配置环境变量等等都是全局的，幸好目前我用的几个插件都支持自定义包的拓展配置，比如 python-mode 和 coc-python。 1. 对于 pymode pymode 提供了 g:pymode_paths 数组来存放额外的包路径，所以在你的 pymode 配置中加入如下配置即可： if $BUILDOUT_EGGS_PATH != &amp;#39;&amp;#39; let g:pymode_paths = reverse(split(globpath($BUILDOUT_EGGS_PATH, &amp;#39;*&amp;#39;), &amp;#39;\n&amp;#39;)) else let g:pymode_paths = reverse(split(globpath(getcwd().&amp;#39;/eggs&amp;#39;, &amp;#39;*&amp;#39;), &amp;#39;\n&amp;#39;)) endif 在上面的配置中，如果你的 buildout 使用了多个项目共享 eggs 模式的话，为 BUILDOUT_EGGS_PATH 配置共享 eggs 的路径即可: export BUILDOUT_EGGS_PATH=/path/to/buildout/eggs/path 而如果并不是共享 eggs 的模式，那么项目的包都会在当前目录下的 eggs 中，就不用任何配置，配置会走到 else 逻辑自动获取包路径。 对于上述配置在 extra-paths 下的包可以: let g:pymode_paths = g:pymode_paths + reverse(split(getcwd().&amp;#39;/my-extra-pkg&amp;#39;, &amp;#39;\n&amp;#39;) 2. 对于 coc-python 同样的，coc-python 也提供了相应的配置： python.autoComplete.extraPaths: List of paths to libraries and the like that need to be imported by auto complete engine. E.g. when using Google App SDK, the paths are not in system path, hence need to be added into this list., default: [] 所以我们只需在 coc-settings.json 中加入相应配置即可，我们依旧使用上面的例子： { // ... &amp;#34;python.autoComplete.extraPaths&amp;#34;:[ &amp;#34;/path/to/local/pro/eggs/pkg1.egg&amp;#34;, &amp;#34;/path/to/local/pro/eggs/pkg2.egg&amp;#34;, &amp;#34;my-extra-pkg&amp;#34; ] // ... } 加入配置之后可以在 neo/vim COMMAND 模式下使用 CocInfo 命令来查看 path 的查找详情。 感兴趣的同学可以查看我的配置，同时也欢迎大家评论留言，与我交流。</description>
    </item>
    
    <item>
      <title>Python3 协程(coroutine)介绍</title>
      <link>https://at7h.com/posts/coroutine/</link>
      <pubDate>Wed, 10 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/coroutine/</guid>
      <description>目前 Python 语言的协程从实现来说可分为两类： 一种是基于传统生成器的协程，叫做 generator-based coroutines，通过包装 generator 对象实现。 另一种在 Python 3.5 版本 PEP 492 诞生，叫做 native coroutines，即通过使用 async 语法来声明的协程。 本文主要介绍第二种，第一种基于生成器的协程已在 Python 3.8 中弃用，并计划在 Python 3.10 中移除。本文是「介绍」，就先不讨论太多实现原理的东西，感兴趣的童鞋可以继续关注后面的文章。 协程(coroutine) 首先，来看一个非常简单的例子： import asyncio async def c(): await asyncio.sleep(1) return &amp;#39;Done 👌&amp;#39; 这个被 async 修饰的函数 c 就是一个协程函数，该函数会返回一个协程对象。 In [1]: asyncio.iscoroutinefunction(c) Out[1]: True In [2]: c() Out[2]: &amp;lt;coroutine object c at 0x107b0f748&amp;gt; In [3]: asyncio.iscoroutine(c()) Out[3]: True 一般来说，协程函数 c 应具有以下特点： 一定会返回一个协程对象，而不管其中是否有 await 表达式。 函数中不能再使用 yield from。 函数内部可通过 await 表达式来挂起自身协程，并等待另一个协程完成直到返回结果。 await 表达式后面可以跟的一定是一个可等待对象，而不仅仅是协程对象。 不可在 async 修饰的协程函数外使用 await 关键字，否则会引发一个 SyntaxError。 当对协程对象进行垃圾收集时，如果从未等待过它，则会引发一个 RuntimeWarning（如果你刚开始写 async，那你一定遇得到，不经意间就会忘掉一个 await)。 下面分别介绍下上面提到的两个概念，可等待对象和协程对象。 可等待对象(awaitable) 我们来看 collections.abc 模块中对 Awaitable 类的定义： class Awaitable(metaclass=ABCMeta): __slots__ = () @abstractmethod def __await__(self): yield @classmethod def __subclasshook__(cls, C): if cls is Awaitable: return _check_methods(C, &amp;#34;__await__&amp;#34;) return NotImplemented 可见，可等待对象主要实现了一个 __await__ 方法。且该方法必须返回一个迭代器(iterator) ①，否则将会引发一个 TypeError。 注意：主要实现是因为 await 表达式需要跟老的基于生成器的协程相兼容，即通过使用 types.coroutine() 或 asyncio.coroutine() 装饰器返回的生成器迭代器对象(generator iterator)也属于可等待对象，但它们并未实现 __await__ 方法。 协程对象(Coroutine) 同样的，我们来看 collections.abc 模块中对 Coroutine 类的定义： class Coroutine(Awaitable): __slots__ = () @abstractmethod def send(self, value): &amp;#34;&amp;#34;&amp;#34;Send a value into the coroutine. Return next yielded value or raise StopIteration. &amp;#34;&amp;#34;&amp;#34; raise StopIteration @abstractmethod def throw(self, typ, val=None, tb=None): &amp;#34;&amp;#34;&amp;#34;Raise an exception in the coroutine. Return next yielded value or raise StopIteration. &amp;#34;&amp;#34;&amp;#34; if val is None: if tb is None: raise typ val = typ() if tb is not None: val = val.with_traceback(tb) raise val def close(self): &amp;#34;&amp;#34;&amp;#34;Raise GeneratorExit inside coroutine. &amp;#34;&amp;#34;&amp;#34; try: self.throw(GeneratorExit) except (GeneratorExit, StopIteration): pass else: raise RuntimeError(&amp;#34;coroutine ignored GeneratorExit&amp;#34;) @classmethod def __subclasshook__(cls, C): if cls is Coroutine: return _check_methods(C, &amp;#39;__await__&amp;#39;, &amp;#39;send&amp;#39;, &amp;#39;throw&amp;#39;, &amp;#39;close&amp;#39;) return NotImplemented 由上可知，由于继承关系，协程对象是属于可等待对象的。 除了协程 Coroutine 对象外，目前常见的可等待对象还有两种：asyncio.Task 和 asyncio.Future，下文中介绍。 协程的执行可通过调用 __await__() 并迭代其结果进行控制。当协程结束执行并返回时，迭代器会引发 StopIteration 异常，并通过该异常的 value 属性来传播协程的返回值。下面看一个简单的例子： In [4]: c().send(None) Out[4]: &amp;lt;Future pending&amp;gt; In [5]: async def c1(): ...: return &amp;#34;Done 👌&amp;#34; ...: In [6]: c1().send(None) Out[6]: StopIteration: Done 👌 运行 协程的运行需要在一个 EventLoop 中进行，由它来控制异步任务的注册、执行、取消等。其大致原理是： 把传入的所有异步对象(准确的说是可等待对象，如 Coroutine，Task 等，见下文)都注册到这个 EventLoop 上，EventLoop 会循环执行这些异步对象，但同时只执行一个，当执行到某个对象时，如果它正在等待其他对象（I/O 处理） 返回，事件循环会暂停它的执行去执行其他的对象。当某个对象完成 I/O 处理后，下次循环到它的时候会获取其返回值然后继续向下执行。这样以来，所有的异步任务就可以协同运行。 EventLoop 接受的对象必须为可等待对象，目前主要有三种类型即 Coroutine, Task 和 Future。 下面简单的介绍下 Task 和 Future： Future 是一种特殊的低级的可等待对象，用来支持底层回调式代码与高层 async/await 式的代码交互，是对协程底层实现的封装，其表示一个异步操作的最终结果。它提供了设置和获取 Future 执行状态或结果等操作的接口。Future 实现了 __await__ 协议，并通过 __iter__ = __await__ 来兼容老式协程。一般来说，我们不需要关心这玩意儿，日常的开发也是不需要要用到它的。如有需要，就用其子类 Task。 Task 用来协同的调度协程以实现并发，并提供了相应的接口供我们使用。 创建一个 Task 非常简单： In [6]: loop = asyncio.get_event_loop() In [7]: task = loop.create_task(c()) In [8]: task Out[8]: &amp;lt;Task pending coro=&amp;lt;c() running at &amp;lt;ipython-input-1-3afd2bbb1944&amp;gt;:3&amp;gt;&amp;gt; In [9]: task.done() Out[9]: False In [10]: task.cancelled() Out[10]: False In [11]: task.result() Out[11]: InvalidStateError: Result is not set. In [12]: await task Out[12]: &amp;#39;Done 👌&amp;#39; In [13]: task Out[13]: &amp;lt;Task finished coro=&amp;lt;c() done, defined at &amp;lt;ipython-input-1-3afd2bbb1944&amp;gt;:3&amp;gt; result=&amp;#39;Done 👌&amp;#39;&amp;gt; In [14]: task.done() Out[14]: True In [15]: task.result() Out[15]: &amp;#39;Done 👌&amp;#39; In [16]: task = loop.create_task(c()) In [17]: task.cancel() Out[17]: True In [18]: await task Out[18]: CancelledError: 上面说到，协程的运行需要在一个 EventLoop 中进行，在 Python 3.7 之前，你只能这么写 😔 : In [19]: loop = asyncio.get_event_loop() In [20]: loop.run_until_complete(c()) Out[20]: &amp;#39;Done 👌&amp;#39; In [21]: loop.close() Python 3.7 及以上版本可以直接使用 asyncio.run() 👏 : In [22]: asyncio.run(c()) Out[22]: &amp;#39;Done 👌&amp;#39; 并发 有些童鞋可能有疑问了，我写好了一个个协程函数，怎样才能并发的运行 🤔 ？ asyncio 提供了相应的两个接口：asyncio.gather 和 asyncio.wait 来支持: async def c1(): await asyncio.sleep(1) print(&amp;#39;c1 done&amp;#39;) return True async def c2(): await asyncio.sleep(2) print(&amp;#39;c2 done&amp;#39;) return True async def c12_by_gather(): await asyncio.gather(c1(), c2()) async def c12_by_awit(): await asyncio.wait([c1(), c2()]) In [23]: asyncio.run(c12_by_gather()) c1 done c2 done In [24]: asyncio.run(c12_by_awit()) c1 done c2 done 其它 上面我们介绍了 PEP 492 coroutine 的基础使用，同时 PEP 492 也相应提出了基于 async with 和 async for 表达式的异步上下文管理器(asynchronous context manager)和异步迭代器(asynchronous iterator)。 下面的介绍的示例将基于 Python 可迭代对象, 迭代器和生成器 里的示例展开，建议感兴趣的同学可以先看下这篇文章。 异步上下文管理器 在 Python 中，我们常会通过实现 __enter__() 和 __exit__() 方法来实现一个上下文管理器： In [1]: class ContextManager: ...: ...: def __enter__(self): ...: print(&amp;#39;enter...&amp;#39;) ...: ...: def __exit__(slef, exc_type, exc_val, exc_tb): ...: print(&amp;#39;exit...&amp;#39;) ...: In [2]: with ContextManager(): ...: print(&amp;#39;Do something...&amp;#39;) ...: enter... Do something... exit... 同样的，在异步编程时我们可以通过实现 __aenter__() 和 __aexit__() 方法来实现一个上下文管理器，并通过 async with 表达式来使用。 In [1]: class AsyncContextManager: ...: ...: async def __aenter__(self): ...: print(&amp;#39;async enter...&amp;#39;) ...: ...: async def __aexit__(slef, exc_type, exc_val, exc_tb): ...: print(&amp;#39;async exit...&amp;#39;) ...: In [2]: async with AsyncContextManager(): ...: print(&amp;#39;Do something...&amp;#39;) ...: async enter... Do something... async exit... 异步迭代 在之前的文章 Python 可迭代对象, 迭代器和生成器 中，我们介绍了通过实现 __iter__() 方法来实现一个可迭代对象，通过实现迭代器协议 __iter__() 和 __next__() 方法来实现一个迭代器对象。下面我们改造下之前的例子，实现一个异步的版本。 class AsyncLinkFinder: PATTERN = &amp;#34;(?&amp;lt;=href=\&amp;#34;).+?(?=\&amp;#34;)|(?&amp;lt;=href=\&amp;#39;).+?(?=\&amp;#39;)&amp;#34; def __init__(self, text): self.links = re.findall(self.PATTERN, text) def __aiter__(self): return AsyncLinkIiterator(self.links) class AsyncLinkIiterator: def __init__(self, links): self.links = links self.index = 0 async def _gen_link(self): try: link = self.links[self.index] self.index += 1 except IndexError: link = None return link def __aiter__(self): return self async def __anext__(self): link = await self._gen_link() if link is None: raise StopAsyncIteration return link In [7]: async for s in AsyncLinkFinder(TEXT): ...: print(s) https://blog.python.org http://feedproxy.google.com/~r/PythonSoftwareFoundationNew/~3/T3r7qZxo-xg/python-software-foundation-fellow.html http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/lE0u-5MIUQc/why-sponsor-pycon-2020.html http://feedproxy.google.com/~r/PythonSoftwareFoundationNews/~3/jAMRqiPhWSs/seeking-developers-for-paid-contract.html 例子中实现了 __aiter__() 方法的 AsyncLinkFinder 就是一个异步可迭代对象，__aiter__() 方法返回的必须是一个异步迭代器，如 AsyncLinkIiterator。异步迭代器必须同时实现 __aiter__() 和 __anext__() 方法。一个不同的点是，异步迭代中，当迭代器耗尽时，需要引发一个 StopAsyncIteration 而不是 StopIteration。 同样的，我们也实现一个异步生成器版本的： class LinkFinder: PATTERN = &amp;#34;(?&amp;lt;=href=\&amp;#34;).+?(?=\&amp;#34;)|(?&amp;lt;=href=\&amp;#39;).+?(?=\&amp;#39;)&amp;#34; def __init__(self, text): self.links = re.finditer(self.PATTERN, text) async def __aiter__(self): return (link.group() for link in self.links) 注 ① 关于迭代器的介绍可阅读 Python 可迭代对象, 迭代器和生成器。 ② 关于示例中 __slots__ 的介绍请查看 理解 Python 类属性之 __slots__。 参考 PEP 492: Coroutines with async and await syntax PEP 342: Coroutines via Enhanced Generators</description>
    </item>
    
    <item>
      <title>Sentry 服务的搭建和使用</title>
      <link>https://at7h.com/posts/sentry-install/</link>
      <pubDate>Wed, 03 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/sentry-install/</guid>
      <description>Sentry 是一个开源的非常强大的实时异常收集系统，可以为开发者的提供帮助、诊断，修复和优化其代码的性能的能力，可以用它来监控线上服务的健康状态，实时收集的异常堆栈信息可以帮助我们快速发现、定位和修复问题。支持 Web 前后端、移动应用以及游戏，90 余种主流语言和相关框架，同时还提供了非常友好的管理页面，错误告警、指派、统计等其他丰富的功能。更多介绍可以查看官方文档。 Sentry 提供了商用的服务，可以直接在官网购买。同时也提供了开源版本，可以自行搭建安装。最近刚好为组里的几个服务搭建和引入 Sentry，就记录下来与大家分享。 Sentry 提供了两种安装方式：docker 和 Python 包。 我这里推荐搭建使用第一种方式，比较简便，否则你需要自行安装和启动 PostgreSQL、Redis、Kafka 等一系列服务和创建表等操作。 本文主要介绍使用 docker 的方式进行安装， 部署 Sentry 环境准备 1. 安装 docker $ curl -sSL https://get.daocloud.io/docker | sh 如果已经安装了其他历史版本，请在安装前先卸载。 2. 安装 docker-compose $ sudo curl -L &amp;quot;https://github.com/docker/compose/releases/download/1.27.1/docker-compose-$(uname -s)-$(uname -m)&amp;quot; -o /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose 查看是否安装成功： $ docker -v Docker version 19.03.1, build 74b1e89 $ docker-compose -v docker-compose version 1.27.1, build 1110ad01 安装 Sentry 1. 获取 onpremise $ git clone https://github.com/getsentry/onpremise.git 2. 执行安装脚本 进入 onpremise 目录执行脚本： $ cd onpremise $ ./install.sh 这个过程稍微有点慢，安装过程中会提示你创建管理者（admin/owner）的账号和密码，请注意留意，按照提示输入即可。 3. 设置邮件等配置 这一步骤是非必须的，启动时会有一个配置的页面，到时候再根据提示填写也是可以的 配置文件为 sentry/config.yml，需要设置邮件、域名等，具体配置可以参见官方文档。 启动服务 安装完成后启动服务: $ docker-compose up -d 然后访问 http://localhost:9000，使用刚刚创建的管理员账号登录。 登录之后会有一个设置页面输入必需的配置，需要你输入一些必需的配置，如 Root URL、 SMTP 服务器等，具体配置参数的意思可以参见官方文档。 如果你在上面的第 3 步已经在 sentry/config.yml 中配置了相关的参数，这里就没有相应的选项了。比如你已经配置了 system.url-prefix（部署服务的域名） 那么这里就没有第一项 Root URL 输入项了。 测试/修改配置 为保证邮箱（SMTP 服务器）配置正确，最好测试一下，进入 admin -&amp;gt; Mail 发送一封测试邮件看看: 测试 SMTP 配置 -- 如果你想更改配置，上图目录视图下点击 Settings 修改即可，修改完成后别忘记重启哦: $ docker-compose down &amp;amp;&amp;amp; docker-compose up -d 接入 Sentry 安装并部署好 sentry 服务后，就可以为你的服务创建一个 project，选择你的语言或者框架: 接着在你的服务项目中接入 sentry 即可: 具体语言或框架的接入文档参见官方接入文档。 问题 1. 正常情况下安装过程中是会出现输入管理员账号密码的步骤的，如果没有创建 admin 账户，可以执行： $ docker-compose run --rm web createuser 具体可以查阅这个 issue。 暂时没遇到其他问题，如果您遇到了欢迎留言，一起探讨，再补充。</description>
    </item>
    
    <item>
      <title>在 tmux 环境中使用 tmux-256color</title>
      <link>https://at7h.com/posts/install-tmux256-formac/</link>
      <pubDate>Mon, 11 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/install-tmux256-formac/</guid>
      <description>在 macOS 中，我们 iTerm2 中的 terminal color 一般都设置为 xterm-256color，这没毛病，但问题是它不能在 tmux 环境中使用: $TERM should be &amp;quot;screen-256color&amp;quot; or &amp;quot;tmux-256color&amp;quot; in tmux. Colors might look wrong. 为此，我们可以在 zshrc 中加上这样一段配置： if [[ $TMUX != &amp;#34;&amp;#34; ]] then export TERM=&amp;#34;tmux-256color&amp;#34; else export TERM=&amp;#34;xterm-256color&amp;#34; fi 而在 tmux 环境中一般默认使用系统自带的 screen-256color，这在大多数情况是够用的，但是它不支持任何斜体字体样式，所以在 Vim 中类似代码高亮这种就会很有问题。 为此，我们可以在 tmux.conf 中加上设置： set -g default-terminal &amp;#34;tmux-256color&amp;#34; set-option -a terminal-overrides &amp;#34;,*256col*:RGB&amp;#34; 新建一个 session 测试一下： tnew test # tmux new -s test 发现报错: can&#39;t find terminal definition for tmux-256color。 原因是系统默认是没有 tmux-256color 的，需要我们手动安装，加上相应的 terminfo 就可以了。 tmux-256color 详细安装教程：Installing tmux-256color for macOS 感兴趣的同学可以参考我的配置，欢迎大家评论留言，与我交流。</description>
    </item>
    
    <item>
      <title>Mac 神器 Karabiner-Elements 推荐</title>
      <link>https://at7h.com/posts/karabiner/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/karabiner/</guid>
      <description>今天给大家推荐一款 Mac 下的键盘键位定制化神器 Karabiner-Elements，你可以用它来尽情随意的修改你的键位设置。 对于程序员来说，键盘 ⌨️ 可谓是最亲近的东西了，毕竟每天摸的最多的就是它 🌝，很多同学都会尝试根据自己的使用习惯来更改键位，以提高输入体验。 我个人比较喜欢小键盘，之前使用 poker2 时就通过 Mac 系统自带的「修饰键更改」功能将大写锁定键改成了 Control，因为大写锁定键几乎没什么用，反而占据了一个绝好的位置。 近期入手了 hhkb，唯一美中不足的是它的方向键有点鸡肋，虽然我是 vim 用户，对方向键的依赖比较小一些，但还是感觉不太方便。一通搜索，发现了一款 Mac 下的键位定制化神器 Karabiner-Elements。将方向键改为 command+hjkl，就直接起飞 😎。 你可以根据需要更换任何键位: 提示： 如果你不清楚你要修改的键叫什么名字，可以使用它自带的 Karabiner-EventViewer 来查看。 如下图，你也可以添加别人配置好的 Rule Mode，点击 『Add rule』即可选择： 没有想要的？试试 『Import more &amp;hellip;』吧： 现在很多键盘都会有一些内置一些键位更改的选项，如 poker，hhkb 等，但支持很有限。如果你想自定义键位，那么 Karabiner-Elements 可以满足你的任何需求。 关于下载安装和使用，请查看官方文档。</description>
    </item>
    
    <item>
      <title>Chrome 网页截图小技巧</title>
      <link>https://at7h.com/posts/screenshot/</link>
      <pubDate>Wed, 25 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>https://at7h.com/posts/screenshot/</guid>
      <description>很多时候，我们都有网页截图的需求，而通常我们都会使用系统截图工具，或是通过 QQ、微信等第三方软件的截图功能来完成。而有时候，需要截取整个网页，对于那些有滚动条的页面来说，上述的截图工具只能截取当前屏幕显示的页面，并不能满足需求。这个时候你可能想借助一些工具插件来完成，但其实 Chrome 开发者工具中已经自带了截图命令，个人觉得效果也令人满意。 所以，下面就来介绍下 Chrome 开发者工具截图命令的使用(mac)： 提示：在此之前，请确保 Chrome 已升级至 59 或更高版本 1. 打开开发者工具：在你想要截图的网页上，按下 F12 或 ⌘Command + ⌥Option + j，也或者右键然后选择「检查」，打开开发者工具。 2. 输入截图命令：随后，按 ⌘Command + ⇧Shift + P 调出命令输入框，然后输入 Capture full size screenshot（只输前几个字母就能找到），找到对应后项然后回车即可。 除了整个网页长截图以外，如果你想准确截取网页的某一部分，没问题！按 ⌘Command + ⇧Shift + C 嗅探元素（即上图中红色框中的那个小箭头），选中想要的部分后，再运行刚才的命令，就可以了。 最后，你还可以进入移动设备模拟的模式下获取手机或者平板的截图，按 ⌘Command + ⇧Shift + M(即上图中红色框中的那个手机的标识)，然后运行刚才的命令就可以啦，在顶部的工具栏中，你还可以选择要模拟的设备和分辨率等。</description>
    </item>
    
  </channel>
</rss>